{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m/home/ehsan/anaconda3/envs/lp_tutorials/bin/xpython: error while loading shared libraries: libxeus.so.13: cannot open shared object file: No such file or directory. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 20000\n",
    "set_size = 60000\n",
    "batch_size = 2\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'\n",
    "\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# Data loader\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "#                                          batch_size=batch_size, \n",
    "#                                          shuffle=True)\n",
    "# Download MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "# Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(mnist_dataset))\n",
    "val_size = len(mnist_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n",
    "\n",
    "# Select a random image from the new training set\n",
    "random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "mnist_images = train_dataloader.dataset.dataset.data\n",
    "mnist_labels = train_dataset.dataset.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 20000\n",
    "set_size = 60000\n",
    "batch_size = 2\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'\n",
    "\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# Data loader\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "#                                          batch_size=batch_size, \n",
    "#                                          shuffle=True)\n",
    "# Download MNIST dataset\n",
    "fashion_mnist_dataset = datasets.FashionMNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "# Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(fashion_mnist_dataset))\n",
    "val_size = len(fashion_mnist_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(fashion_mnist_dataset, [train_size, val_size])\n",
    "\n",
    "# Select a random image from the new training set\n",
    "random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "fashion_mnist_images = train_dataloader.dataset.dataset.data\n",
    "fashion_mnist_labels = train_dataset.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                # Convert to tensor\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert RGB to Grayscale\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "\n",
    "# # Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# # Select a random image from the new training set\n",
    "# random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "cifar_images = torch.tensor(train_dataloader.dataset.dataset.data).permute(0, 3, 1, 2)  # Convert to Tensor & Normalize\n",
    "\n",
    "# cifar_images = train_dataloader.dataset.dataset.data\n",
    "cifar_labels = train_dataset.dataset.targets\n",
    "\n",
    "to_grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "cifar_gray = torch.stack([to_grayscale(img) for img in cifar_images]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_synthetic_images(synthetic_images, label_idx, set_name = 'cifar-rgb', number_of_rows_and_columns = 10):\n",
    "    num_bands = synthetic_images.shape[0]\n",
    "    pixel_size = synthetic_images.shape[-1]\n",
    "    fig, axs = plt.subplots(number_of_rows_and_columns, number_of_rows_and_columns, figsize=(number_of_rows_and_columns, number_of_rows_and_columns))\n",
    "    idx = -1\n",
    "    synthetic_image = synthetic_images[:,0,:,:]\n",
    "    correction_matrix = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    mean_vecotr_data = torch.zeros(num_bands, pixel_size**2)\n",
    "    for idx_i in range(number_of_rows_and_columns):\n",
    "        for idx_j in range (0, number_of_rows_and_columns):\n",
    "            idx += 1\n",
    "            for band_idx in range(num_bands):\n",
    "                tmp = synthetic_images[band_idx, idx, :, :]\n",
    "                synthetic_image[band_idx, :, :] = tmp\n",
    "\n",
    "            if num_bands == 3:\n",
    "                axs[idx_i,idx_j].imshow(synthetic_image.permute(1,2,0), vmin=0, vmax=1)\n",
    "            else:\n",
    "                axs[idx_i,idx_j].imshow(synthetic_image.permute(1,2,0), cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "            axs[idx_i,idx_j].set_xticks([])  # Hide x-ticks\n",
    "            axs[idx_i,idx_j].set_yticks([])  # Hide x-ticks\n",
    "    fig.suptitle('Fake ' + set_name + ' images')\n",
    "    plt.savefig('fake-' + set_name + '-class-'+ str(label_idx) +'.pdf')\n",
    "    plt.close(fig)  # Close figure to free memory\n",
    "\n",
    "def compute_mean_and_covariance_in_data_space(images, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix of the dataset, ensuring it is positive definite.\n",
    "    \"\"\"\n",
    "    images = images.float()  # Ensure floating-point type\n",
    "    images = images.view(images.shape[0], -1)  # Flatten images\n",
    "    mean_vector = torch.mean(images, dim=0, keepdim=True)\n",
    "    centered_images = images - mean_vector\n",
    "    covariance_matrix = torch.matmul(centered_images.T, centered_images) / (images.shape[0] - 1)\n",
    "    \n",
    "    # Regularization: Add a small identity matrix to ensure positive definiteness\n",
    "    covariance_matrix += epsilon * torch.eye(covariance_matrix.shape[0])\n",
    "    \n",
    "    return covariance_matrix, mean_vector\n",
    "\n",
    "def generate_random_uniform_images_from_gaussian(covariance_matrix_gaussian, num_samples = 1):\n",
    "    vector_size = covariance_matrix_gaussian.size(0)\n",
    "    num_pixels = int(vector_size**0.5)\n",
    "    mean = torch.zeros(vector_size, device=covariance_matrix_gaussian.device)\n",
    "    \n",
    "    # Create the multivariate normal distribution\n",
    "    mvn = torch.distributions.MultivariateNormal(\n",
    "        loc=mean,\n",
    "        covariance_matrix=covariance_matrix_gaussian\n",
    "    )\n",
    "    \n",
    "    # Generate samples\n",
    "    gaussian_samples = mvn.rsample((num_samples,))\n",
    "    uniform_samples = 0.5 * (1 + torch.erf(gaussian_samples / np.sqrt(2)))  # Convert Gaussian to Uniform [0,1]\n",
    "    return uniform_samples.reshape(num_samples, num_pixels, num_pixels)\n",
    "\n",
    "\n",
    "def generate_random_uniform_images(covariance_matrix, num_samples = 1):\n",
    "    \"\"\"\n",
    "    Generate samples from a multivariate normal distribution with mean 0 and given covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        covariance_matrix (torch.Tensor): Covariance matrix of shape (num_pixels, num_pixels).\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of shape (num_samples, num_pixels) containing the samples.\n",
    "    \"\"\"\n",
    "    vector_size = covariance_matrix.size(0)\n",
    "    num_pixels = int(vector_size**0.5)\n",
    "    mean = torch.zeros(vector_size, device=covariance_matrix.device)\n",
    "    \n",
    "    # Create the multivariate normal distribution\n",
    "    mvn = torch.distributions.MultivariateNormal(\n",
    "        loc=mean,\n",
    "        covariance_matrix=covariance_matrix\n",
    "    )\n",
    "    \n",
    "    # Generate samples\n",
    "    gaussian_samples = mvn.rsample((num_samples,))\n",
    "    uniform_samples = 0.5 * (1 + torch.erf(gaussian_samples / np.sqrt(2)))  # Convert Gaussian to Uniform [0,1]\n",
    "    return uniform_samples.reshape(num_samples, num_pixels, num_pixels)\n",
    "\n",
    "def compute_gaussian_covariance_from_uniform(covariance_matrix_unifrom, epsilon = 1e-4):\n",
    "    \"\"\"\n",
    "    Compute the Gaussian covariance matrix from the uniform covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "        covariance_matrix_unifrom (torch.Tensor): Covariance matrix of the uniforms, shape (d, d).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Gaussian covariance matrix, shape (d, d).\n",
    "    \"\"\"\n",
    "    # Compute Pearson correlation matrix of the uniforms\n",
    "    diag_var_u = torch.diag(covariance_matrix_unifrom)  # Variances of uniforms (should be ~1/12)\n",
    "    std_u = torch.sqrt(diag_var_u)    # Standard deviations of uniforms\n",
    "    outer_std = torch.outer(std_u, std_u)\n",
    "    R_u = covariance_matrix_unifrom / outer_std         # Pearson correlation matrix of uniforms\n",
    "\n",
    "    # Compute Gaussian correlation matrix\n",
    "    R_n = 2 * torch.sin((math.pi / 6) * R_u)\n",
    "\n",
    "    # Ensure diagonal is exactly 1 (due to numerical precision)\n",
    "    R_n.fill_diagonal_(1.0)\n",
    "    covariance_matrix_gaussian =  R_n + torch.eye(R_u.shape[0])\n",
    "    return covariance_matrix_gaussian\n",
    "\n",
    "def compute_pixel_cdf_map(images, max_pixel_value = 255):\n",
    "    \"\"\"\n",
    "    Compute the empirical CDF for each pixel position across all images.\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): Tensor of shape (num_samples, pixel_size, pixel_size),\n",
    "                               containing grayscale images with integer pixel values (0-255).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (pixel_size**2, 256), where each row contains\n",
    "                      the empirical CDF for a given pixel position.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples, pixel_size, _ = images.shape\n",
    "    # max_pixel_value = images.max()\n",
    "    \n",
    "    # Flatten images along the pixel dimension\n",
    "    images_flat = images.view(num_samples, -1)  # Shape: (num_samples, pixel_size**2)\n",
    "    \n",
    "    # Initialize the CDF map\n",
    "    cdf_map = torch.zeros((images_flat.shape[1], max_pixel_value + 1), device=images.device)\n",
    "    \n",
    "    # Compute the empirical CDF for each pixel location\n",
    "    for i in range(images_flat.shape[1]):\n",
    "        pixel_values = images_flat[:, i]  # All values for a specific pixel position\n",
    "        hist = torch.bincount(pixel_values, minlength=max_pixel_value + 1).float()  # Count occurrences\n",
    "        cdf_map[i] = hist.cumsum(dim=0) / num_samples  # Normalize to get CDF\n",
    "    \n",
    "    return cdf_map\n",
    "import torch\n",
    "\n",
    "def transform_dataset_to_uniform_distribution(images, cdf_map, reverse=False):\n",
    "    \"\"\"\n",
    "    Transform the dataset into a uniform [0,1] dataset using pixel-wise empirical CDF.\n",
    "    If reverse=True, transform back to the original space.\n",
    "\n",
    "    Args:\n",
    "        images (torch.Tensor): Input dataset of shape (num_samples, pixel_size, pixel_size).\n",
    "                               If reverse=False, dtype=torch.uint8; if reverse=True, dtype=torch.float32.\n",
    "        cdf_map (torch.Tensor): Empirical CDF map of shape (pixel_size**2, 256).\n",
    "        reverse (bool): If True, transform back to the original pixel space.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Transformed dataset of the same shape as input.\n",
    "    \"\"\"\n",
    "    num_samples, pixel_size, _ = images.shape\n",
    "    images_flat = images.view(num_samples, -1)  # Flatten for batch processing\n",
    "    cdf_map = cdf_map.to(images.device)  # Ensure cdf_map is on the same device\n",
    "\n",
    "    if not reverse:\n",
    "        # Forward transformation: Map pixel values to uniform [0,1]\n",
    "        images_flat = images_flat.long()  # Convert to long for indexing\n",
    "        transformed_images_flat = cdf_map[torch.arange(images_flat.shape[1], device=images.device).unsqueeze(0), images_flat]\n",
    "        \n",
    "        # Reshape and ensure float output\n",
    "        transformed_images = transformed_images_flat.view(num_samples, pixel_size, pixel_size).to(torch.float32)\n",
    "        # gaussian_images = torch.erfinv(2 * transformed_images - 1) * torch.sqrt(torch.tensor(2.0))\n",
    "        return transformed_images#, gaussian_images\n",
    "\n",
    "    else:\n",
    "        # Reverse transformation: Map uniform values back to pixel space\n",
    "        pixel_positions = torch.arange(cdf_map.shape[0], device=images.device)\n",
    "\n",
    "        # Use `searchsorted` for **each** pixel position separately\n",
    "        transformed_images_flat = torch.stack([\n",
    "            torch.searchsorted(cdf_map[i], images_flat[:, i], right=True) for i in range(cdf_map.shape[0])\n",
    "        ], dim=1).clip(0, 255)  # Shape (num_samples, pixel_size**2)\n",
    "\n",
    "        # Reshape and ensure byte output\n",
    "        transformed_images = transformed_images_flat.view(num_samples, pixel_size, pixel_size).to(torch.uint8)\n",
    "        return transformed_images / 255\n",
    "\n",
    "def plot_histogram_of_data(data: torch.Tensor, bins: int = 50, color: str = 'blue',\n",
    "                     title: str = 'Empirical PDF', xlabel: str = 'Value', \n",
    "                     ylabel: str = 'Density') -> tuple[plt.Figure, plt.Axes]:\n",
    "    if type(data) == list and len(data) > 1:\n",
    "        num_of_plots = len(data)\n",
    "        fig, ax = plt.subplots(1, num_of_plots, figsize=(5*num_of_plots, 5), tight_layout=True)\n",
    "        for i in range(num_of_plots):\n",
    "            data_np = data[i].flatten().cpu().numpy()  # Handles GPU tensors\n",
    "            ax[i].hist(data_np, bins=bins, density=True, alpha=0.6, color=color, label='Empirical PDF')\n",
    "            ax[i].axhline(1.0, color='black', linestyle='--', label='Uniform PDF')\n",
    "            ax[i].set_title(title)\n",
    "            ax[i].set_xlabel(xlabel)\n",
    "            ax[i].set_ylabel(ylabel)\n",
    "            ax[i].legend()\n",
    "        return fig, ax\n",
    "    elif type(data) == list and len(data) == 1:\n",
    "        data_np = data[0].flatten().cpu().numpy()  # Handles GPU tensors\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 5), tight_layout=True)\n",
    "        ax.hist(data_np, bins=bins, density=True, alpha=0.6, color=color, label='Empirical PDF')\n",
    "        ax.axhline(1.0, color='black', linestyle='--', label='Uniform PDF')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "        return fig, ax\n",
    "    elif torch.is_tensor(data):\n",
    "        data_np = data.flatten().cpu().numpy()  # Handles GPU tensors\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 5), tight_layout=True)\n",
    "        ax.hist(data_np, bins=bins, density=True, alpha=0.6, color=color, label='Empirical PDF')\n",
    "        ax.axhline(1.0, color='black', linestyle='--', label='Uniform PDF')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "        return fig, ax\n",
    "    \n",
    "\n",
    "def min_max_normalization(data):\n",
    "    data = data\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "def transform_data_to_have_the_true_covariance(input_images, covariance_matrix_true, mean_value = 0, ifCholesky = False):\n",
    "\n",
    "    if not ifCholesky:\n",
    "        pixel_size = input_images.shape[-1]\n",
    "        eigenvalues_data, eigenvector_data = torch.linalg.eig(covariance_matrix_true)\n",
    "        eigenvector_data = eigenvector_data.real\n",
    "        eigenvalues_data = eigenvalues_data.real\n",
    "        correction_matrix = torch.matmul(eigenvector_data,torch.diag(eigenvalues_data)**.5)\n",
    "        # correction_matrix = eigenvector_data.T\n",
    "        \n",
    "        # print(input_images.min(), input_images.max())\n",
    "        input_images = (input_images -  mean_value)\n",
    "        transformed_images = torch.matmul(correction_matrix.unsqueeze(0), input_images.reshape(-1,pixel_size**2,1)).reshape(-1, pixel_size, pixel_size)\n",
    "\n",
    "        # print(input_images.min(), input_images.max())\n",
    "        return transformed_images\n",
    "    else:\n",
    "        num_samples, pixel_size, _ = input_images.shape\n",
    "        p2 = pixel_size ** 2  # Flattened pixel count\n",
    "\n",
    "        # Flatten images\n",
    "        input_images_flat = input_images.view(num_samples, p2)\n",
    "\n",
    "\n",
    "        # Compute empirical covariance of input samples\n",
    "        mean_input = input_images_flat.mean(dim=0, keepdim=True)\n",
    "        centered_input = input_images_flat - mean_input\n",
    "        covariance_input = (centered_input.T @ centered_input) / (num_samples - 1)\n",
    "\n",
    "        # Compute Cholesky decomposition (or Eigen decomposition)\n",
    "        L_real = torch.linalg.cholesky(covariance_matrix_true)  # L_real @ L_real.T = covariance_matrix_true\n",
    "        L_input = torch.linalg.cholesky(covariance_input)  # L_input @ L_input.T = covariance_input\n",
    "\n",
    "        # Compute correction matrix A\n",
    "        correction_matrix = L_real @ torch.linalg.inv(L_input)\n",
    "\n",
    "        # Apply correction matrix\n",
    "        transformed_images_flat = (input_images_flat - mean_input) @ correction_matrix.T\n",
    "        transformed_images = transformed_images_flat.view(num_samples, pixel_size, pixel_size)\n",
    "\n",
    "        return transformed_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_fake_images(real_images, fake_images, lr=0.01, num_epochs=500):\n",
    "    \"\"\"\n",
    "    Finds a linear correction matrix A such that:\n",
    "    Cov(A * fake_images) = Cov(real_images)\n",
    "    \n",
    "    Args:\n",
    "        real_images (torch.Tensor): Tensor of real images of shape (num_samples, pixel_size, pixel_size).\n",
    "        fake_images (torch.Tensor): Tensor of fake images of shape (num_samples, pixel_size, pixel_size).\n",
    "        lr (float): Learning rate for gradient descent.\n",
    "        num_epochs (int): Number of optimization steps.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Correction matrix A of shape (pixel_size**2, pixel_size**2).\n",
    "    \"\"\"\n",
    "    lr_first = lr\n",
    "    num_samples, pixel_size, _ = real_images.shape\n",
    "    p2 = pixel_size**2  # Number of pixels squared\n",
    "    \n",
    "    # Flatten images for matrix operations\n",
    "    X = real_images.view(num_samples, p2)\n",
    "    Y = fake_images.view(num_samples, p2)\n",
    "\n",
    "    # Compute empirical covariance matrices\n",
    "    X_mean = X.mean(dim=0, keepdim=True)\n",
    "    Y_mean = Y.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    Sigma_X = (X - X_mean).T @ (X - X_mean) / (num_samples - 1)\n",
    "    Sigma_Y = (Y - Y_mean).T @ (Y - Y_mean) / (num_samples - 1)\n",
    "\n",
    "    # Initialize correction matrix A (identity matrix)\n",
    "    A = torch.eye(p2, requires_grad=True)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([A], lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute transformed covariance\n",
    "        transformed_cov = A @ Sigma_Y @ A.T\n",
    "        \n",
    "        # Loss function: Frobenius norm difference\n",
    "        loss = torch.norm(Sigma_X - transformed_cov, p='fro')\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Enforce pixel constraints\n",
    "        with torch.no_grad():\n",
    "            A.clamp_(0, 255)\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss.item()}, learning rate = {lr}\")\n",
    "        if loss.item() <= 0.5: lr = lr_first / 100\n",
    "        elif loss.item() <= 0.8: lr = lr_first / 50\n",
    "        elif loss.item() <= 1: lr = lr_first / 10\n",
    "        else: lr = lr_first\n",
    "\n",
    "    correction_matrix = A.detach()\n",
    "    corrected_fake_images = torch.matmul(fake_images.view(num_samples, -1), correction_matrix.T).view(num_samples, pixel_size, pixel_size)\n",
    "    return corrected_fake_images\n",
    "\n",
    "def correct_fake_images_svd(real_images, fake_images):\n",
    "    \"\"\"\n",
    "    Compute correction matrix A such that Cov(A * fake_images) = Cov(real_images).\n",
    "\n",
    "    Args:\n",
    "        real_images (torch.Tensor): (num_samples, pixel_size, pixel_size)\n",
    "        fake_images (torch.Tensor): (num_samples, pixel_size, pixel_size)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Correction matrix A (pixel_size^2, pixel_size^2)\n",
    "    \"\"\"\n",
    "    num_samples, pixel_size, _ = real_images.shape\n",
    "    p2 = pixel_size ** 2  # Total pixels per image\n",
    "\n",
    "    # Flatten images\n",
    "    real_images_flat = real_images.view(num_samples, -1).float()\n",
    "    fake_images_flat = fake_images.view(num_samples, -1).float()\n",
    "\n",
    "    # Compute empirical covariance matrices\n",
    "    centered_real = real_images_flat - real_images_flat.mean(dim=0, keepdim=True)\n",
    "    centered_fake = fake_images_flat - fake_images_flat.mean(dim=0, keepdim=True)\n",
    "\n",
    "    covariance_real = (centered_real.T @ centered_real) / (num_samples - 1)\n",
    "    covariance_fake = (centered_fake.T @ centered_fake) / (num_samples - 1)\n",
    "\n",
    "    # SVD decomposition\n",
    "    U_real, S_real, V_real_T = torch.svd(covariance_real)\n",
    "    U_fake, S_fake, V_fake_T = torch.svd(covariance_fake)\n",
    "\n",
    "    # Construct correction matrix A\n",
    "    sqrt_S_real = torch.diag(torch.sqrt(S_real))\n",
    "    inv_sqrt_S_fake = torch.diag(1.0 / torch.sqrt(S_fake))\n",
    "\n",
    "    correction_matrix = U_real @ sqrt_S_real @ V_real_T @ V_fake_T.T @ inv_sqrt_S_fake @ U_fake.T\n",
    "    \n",
    "    corrected_fake_images = torch.matmul(fake_images.view(num_samples, -1), correction_matrix.T).view(num_samples, pixel_size, pixel_size)\n",
    "    return corrected_fake_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_uniform_random_cifar_rgb_per_class(label_idx, set_name = 'cifar-rgb', epsilon = 0):\n",
    "    num_bands = 1\n",
    "    if set_name == 'mnist':\n",
    "        images = mnist_images\n",
    "        train_images = mnist_images[mnist_labels == label_idx]\n",
    "        pixel_size = images.shape[2]\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'fashion-mnist':\n",
    "        images = fashion_mnist_images[fashion_mnist_labels == label_idx]\n",
    "        pixel_size = images.shape[2]\n",
    "        train_images = fashion_mnist_images[fashion_mnist_labels == label_idx]\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'cifar-gray':\n",
    "        pixel_size = cifar_images.shape[2]\n",
    "        train_images = cifar_gray[torch.tensor(cifar_labels) == label_idx,:,:].squeeze(dim=1)\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'cifar-rgb':\n",
    "        num_bands = 3\n",
    "        pixel_size = cifar_images.shape[2]\n",
    "        train_images = cifar_images[torch.tensor(cifar_labels) == label_idx,:,:,:] \n",
    "        # train_images = torch.zeros(5000, 3, pixel_size, pixel_size)\n",
    "        # for band_idx in range(num_bands): \n",
    "            # train_images = cifar_images[torch.tensor(cifar_labels) == label_idx,band_idx,:,:].squeeze(dim=1)\n",
    "    else: return [], []\n",
    "    # print(train_images.shape)\n",
    "    num_samples = train_images.shape[0]\n",
    "    train_images = train_images.reshape(num_bands*num_samples, pixel_size, pixel_size)\n",
    "    pixel_cdf_map = compute_pixel_cdf_map(train_images.reshape(num_bands*num_samples, pixel_size, pixel_size))\n",
    "    uniform_real_images = transform_dataset_to_uniform_distribution(train_images, pixel_cdf_map, reverse=False)\n",
    "    # uniform_real_images, _ = transform_dataset_to_uniform_and_gaussian_vectorized(train_images)\n",
    "    covariance_matrix_real_images, _ = compute_mean_and_covariance_in_data_space(train_images, epsilon=epsilon)\n",
    "    covariance_matrix_real_uniform, _ = compute_mean_and_covariance_in_data_space(uniform_real_images, epsilon=epsilon)\n",
    "\n",
    "\n",
    "    # uniform_fake_images = generate_random_uniform_images(covariance_matrix_real_uniform, num_samples = num_samples*num_bands)\n",
    "    # uniform_fake_images = transform_data_to_have_the_true_covariance(uniform_fake_images.float(), covariance_matrix_real_uniform.float(), mean_value = uniform_fake_images.float().mean(dim=0), ifCholesky=True)\n",
    "    \n",
    "    \n",
    "    # covariance_matrix_real_gaussian = torch.eye(pixel_size**2)\n",
    "    covariance_matrix_real_gaussian = compute_gaussian_covariance_from_uniform(covariance_matrix_real_uniform, epsilon = epsilon)\n",
    "    covariance_matrix_real_gaussian = covariance_matrix_real_gaussian -0.5*torch.diag(torch.diag(covariance_matrix_real_gaussian))\n",
    "    uniform_fake_images = generate_random_uniform_images_from_gaussian(covariance_matrix_real_gaussian, num_samples= num_samples*num_bands)\n",
    "\n",
    "    tmp = uniform_fake_images\n",
    "    # uniform_fake_images = transform_data_to_have_the_true_covariance(uniform_fake_images.float(), covariance_matrix_real_uniform.float(), mean_value = uniform_fake_images.float().mean(dim=0))\n",
    "    \n",
    "    # uniform_fake_images = correct_fake_images(uniform_real_images, uniform_fake_images, num_epochs=1000, lr=0.001)\n",
    "    # uniform_fake_images = correct_fake_images_svd(uniform_real_images, uniform_fake_images)\n",
    "    uniform_fake_images =  improve_fake_images_gan(uniform_real_images, uniform_fake_images, num_epochs=1000, lr=0.00005)\n",
    "    # uniform_fake_images = min_max_normalization(uniform_fake_images) #/ 255\n",
    "    print(uniform_fake_images.min(), uniform_fake_images.max())\n",
    "    \n",
    "    \n",
    "    plot_histogram_of_data([uniform_real_images, tmp,uniform_fake_images])\n",
    "    # uniform_fake_images = torch.rand(num_bands*num_samples,pixel_size,pixel_size)\n",
    "    # uniform_fake_images = transform_data_to_have_the_true_covariance(uniform_fake_images, covariance_matrix_real_uniform)\n",
    "    \n",
    "    covariance_matrix_fake_uniform, _= compute_mean_and_covariance_in_data_space(uniform_fake_images, epsilon=epsilon)\n",
    "    print(f\"Covarinace difference norm: {(covariance_matrix_real_uniform - covariance_matrix_fake_uniform).norm()}\")\n",
    "\n",
    "\n",
    "    synthetic_images = transform_dataset_to_uniform_distribution(uniform_fake_images, pixel_cdf_map, reverse=True) \n",
    "\n",
    "    # synthetic_images = transform_data_to_have_the_true_covariance(synthetic_images.float(), covariance_matrix_real_images.float(), mean_value = synthetic_images.float().mean(dim=0)/5, ifCholesky=False)\n",
    "    print(synthetic_images.min(), synthetic_images.max())\n",
    "    # synthetic_images = min_max_normalization(synthetic_images)\n",
    "\n",
    "    return uniform_real_images, uniform_fake_images, synthetic_images.reshape(num_bands, num_samples, pixel_size, pixel_size)\n",
    " \n",
    "num_classes = 10\n",
    "set_name = 'mnist'\n",
    "set_name = 'fashion-mnist'\n",
    "# set_name = 'cifar-rgb'\n",
    "set_name = 'cifar-gray'\n",
    "ifPlot = True\n",
    "# if num_samples <= 100: ifPlot = True\n",
    "# for label_idx in range(0,num_classes): \n",
    "for label_idx in range(7,8):\n",
    "    print(f\"Class: {label_idx}\" , end=\"\\r\")\n",
    "    # uniform_cifar_real_images[label_idx*5000:(1+label_idx)*5000,:,:,:], uniform_cifar_fake_images[label_idx*5000:(1+label_idx)*5000] = generate_uniform_random_cifar_rgb_per_class(label_idx, num_samples, ifPlot = False)\n",
    "    _, _,synthetic_images = generate_uniform_random_cifar_rgb_per_class(label_idx, set_name = set_name, epsilon = 1e-12)\n",
    "    plot_synthetic_images(synthetic_images, label_idx, set_name=set_name, number_of_rows_and_columns=5)\n",
    "os.system(f\"pdftk fake-{set_name}-class-*.pdf output fake-{set_name}.pdf\")\n",
    "os.system(f\"rm fake-{set_name}*class*\")\n",
    "    # print(tmp1.shape, tmp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# # Define the Generator (Neural Network)\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, pixel_size):\n",
    "#         super(Generator, self).__init__()\n",
    "#         input_size = pixel_size**2\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(input_size, input_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(input_size, input_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(input_size, input_size),\n",
    "#             nn.ReLU(),\n",
    "#             # nn.Linear(512, 1024),\n",
    "#             # nn.ReLU(),\n",
    "#             # nn.Linear(1024, input_size),\n",
    "#             nn.Tanh()  # Output between [-1, 1]\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(x.shape[0], -1)  # Flatten\n",
    "#         x = self.model(x)\n",
    "#         x = (x + 1) / 2   # Rescale to [0, 255]\n",
    "#         return x.view(-1, pixel_size, pixel_size)  # Reshape to image size\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, pixel_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.pixel_size = pixel_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 2, kernel_size=4, stride=2, padding=1),  # (B, 64, pixel_size, pixel_size)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(2, 4, kernel_size=4, stride=2, padding=1),  # (B, 128, 2*pixel_size, 2*pixel_size)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(4, 1, kernel_size=3, stride=1, padding=1),  # (B, 1, 2*pixel_size, 2*pixel_size)\n",
    "            nn.Tanh()  # Output range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, self.pixel_size, self.pixel_size)  # Reshape input\n",
    "        x = self.model(x)\n",
    "        x = (x + 1) / 2 * 255  # Rescale to [0, 255]\n",
    "        return x.view(-1, self.pixel_size * 2, self.pixel_size * 2)  # Reshape to imag\n",
    "\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, pixel_size):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.pixel_size = pixel_size\n",
    "#         self.A = nn.Parameter(torch.eye(pixel_size**2))  # Learnable correction matrix\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return torch.matmul(x, self.A.T).view(num_samples, pixel_size, pixel_size)  # Apply correction matrix\n",
    "\n",
    "# Define the Discriminator (Neural Network)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, pixel_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        input_size = pixel_size**2\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Probability of being real\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)  # Flatten\n",
    "        return self.model(x)\n",
    "\n",
    "# Training function\n",
    "def improve_fake_images_gan(real_images, fake_images, num_epochs=1000, lr=0.0002):\n",
    "    num_samples, pixel_size, _ = real_images.shape\n",
    "\n",
    "    # Flatten images\n",
    "    X = real_images.view(num_samples, -1) / 255  # Normalize to [0,1]\n",
    "    Y = fake_images.view(num_samples, -1) / 255\n",
    "\n",
    "    # Initialize models\n",
    "    G = Generator(pixel_size)\n",
    "    D = Discriminator(pixel_size)\n",
    "    \n",
    "\n",
    "    # Optimizers and Loss Function\n",
    "    optimizer_G = optim.Adam(G.parameters(), lr=lr)\n",
    "    optimizer_D = optim.Adam(D.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # === Train Discriminator ===\n",
    "        optimizer_D.zero_grad()\n",
    "        real_labels = torch.ones(num_samples, 1)\n",
    "        fake_labels = torch.zeros(num_samples, 1)\n",
    "\n",
    "        real_loss = criterion(D(X), real_labels)\n",
    "        fake_loss = criterion(D(G(Y).detach()), fake_labels)\n",
    "\n",
    "        D_loss = real_loss + 10*fake_loss\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        optimizer_G.zero_grad()\n",
    "        G_loss = 10*criterion(D(G(Y)), real_labels)  # Fool D\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: D_loss = {D_loss.item():.4f}, G_loss = {G_loss.item():.4f}\")\n",
    "\n",
    "    corrected_fake_images = G(Y)#.clamp(0, 255)  # Ensure valid pixel range\n",
    "    \n",
    "    return corrected_fake_images.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'AttributeError'>",
     "evalue": "module 'torch' has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m uniform_samples_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed_datasets/cifar-gray_uniform_samples.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m(uniform_samples_dict[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],uniform_samples_dict[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] , dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lp_tutorials/lib/python3.12/site-packages/torch/__init__.py:2681\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _lazy_modules:\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m-> 2681\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "uniform_samples_dict = torch.load('transformed_datasets/cifar-gray_uniform_samples.pth')\n",
    "\n",
    "torch.cat(uniform_samples_dict[0][0],uniform_samples_dict[0][0] , dim = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python . (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
