{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839aae7b-221d-430b-a566-bbea48547bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 210\u001b[0m\n\u001b[1;32m    207\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(X,K,N,dim)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# optimizer = tf.keras.optimizers.RMSprop(0.001)\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# optimizer =  keras.optimizers.SGD(lr=1e-3, clipnorm=1.)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \n\u001b[1;32m    213\u001b[0m \n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# In[ ]:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mmyloss,optimizer\u001b[38;5;241m=\u001b[39moptimizer,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, myloss])\n",
      "File \u001b[0;32m~/anaconda3/envs/nn/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/adam.py:104\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     88\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    103\u001b[0m ):\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjit_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_learning_rate(learning_rate)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1 \u001b[38;5;241m=\u001b[39m beta_1\n",
      "File \u001b[0;32m~/anaconda3/envs/nn/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1053\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1040\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1050\u001b[0m ):\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new Optimizer.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjit_compile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n",
      "File \u001b[0;32m~/anaconda3/envs/nn/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:89\u001b[0m, in \u001b[0;36m_BaseOptimizer.__init__\u001b[0;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iteration_variable()\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nn/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:118\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m legacy_kwargs:\n\u001b[0;32m--> 118\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    119\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated in the new Keras optimizer, please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck the docstring for valid arguments, or use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy optimizer, e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         )\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid argument, kwargs should be empty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: decay is deprecated in the new Keras optimizer, pleasecheck the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Here is your code\n",
    "\n",
    "# ### Intialize the system\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "### Test\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scenario import scenario\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "from calcMSE import calcMSE\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "from rss_transform import rss_transform\n",
    "from build_model_FF import build_model\n",
    "# from myloss import myloss\n",
    "\n",
    "K = 20\n",
    "dim = 2\n",
    "alpha = 2\n",
    "beta = 1\n",
    "w = 1000\n",
    "target_seed = 0\n",
    "sensor_seed = 1\n",
    "pmin = 1\n",
    "pmax = 1\n",
    "scaler_file = 'minmax_scaler.sav'\n",
    "log_base = np.exp(1)\n",
    "\n",
    "N = 2\n",
    "M = int(1e5)\n",
    "EPOCHS = 10000\n",
    "learn_rate = float(3*1e-6)\n",
    "beta1_val = 0.9\n",
    "beta2_val = 0.99\n",
    "decay_val = int(1e-4)\n",
    "lam = 1\n",
    "\n",
    "\n",
    "\n",
    "if_y_scale = False\n",
    "if_x_scale = False\n",
    "if_sensor_scale = False\n",
    "\n",
    "\n",
    "if_y_scale = True\n",
    "if_x_scale = True\n",
    "if_sensor_scale = True\n",
    "scaling_type = \"maxmin\"\n",
    "scaling_type = \"multiply\"\n",
    "\n",
    "\n",
    "\n",
    "# # Scale the data\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "rss, pos_target, pos_sensor = scenario(N,K,dim,alpha,beta,M,pmax,pmin,w,sensor_seed,target_seed)\n",
    "Y = np.squeeze(pos_target,axis=2)\n",
    "X = rss_transform(rss,log_base)\n",
    "\n",
    "for n in range(0,N):\n",
    "    plt.scatter(Y[:,n,0],Y[:,n,1])\n",
    "# print(Y[:1,:])\n",
    "plt.xlim([-w,w])\n",
    "plt.ylim([-w,w])\n",
    "\n",
    "\n",
    "# scaler_X = StandardScaler()\n",
    "# scaler_Y = StandardScaler()\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# scaler_X =  Normalizer()\n",
    "# scaler_Y =  Normalizer()\n",
    "\n",
    "scaler_X.fit(X)\n",
    "if if_x_scale ==True:\n",
    "    X = scaler_X.transform(X)\n",
    "\n",
    "if if_y_scale == True:\n",
    "    if scaling_type == \"maxmin\":\n",
    "        y = Y.reshape(-1,1)\n",
    "        scaler_Y.fit(y)\n",
    "        y_scaled = scaler_Y.transform(y)\n",
    "        Y = y_scaled.reshape(((np.size(Y,0),np.size(Y,1),np.size(Y,2))))    \n",
    "        if if_sensor_scale == True:\n",
    "            y = pos_sensor.reshape(-1,1)    \n",
    "            y_scaled = scaler_Y.transform(y)\n",
    "            pos_sensor = y_scaled.reshape(((np.size(pos_sensor,0),np.size(pos_sensor,1),np.size(pos_sensor,2),np.size(pos_sensor,3))))    \n",
    "    elif scaling_type == \"multiply\":\n",
    "        Y = Y / w\n",
    "        if if_sensor_scale == True:\n",
    "            pos_sensor = pos_sensor / w\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "for n in range(0,N):\n",
    "    plt.scatter(Y[:,n,0],Y[:,n,1])\n",
    "# plt.xlim([-0.5,0.5])\n",
    "# plt.ylim([-0.5,0.5])\n",
    "\n",
    "plt.scatter(pos_sensor[:,:,:,0],pos_sensor[:,:,:,1])\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def myloss(y_true,y_pred):\n",
    "#     N = tf.shape(y_true).get_shape().as_list()\n",
    "    distance = tf.norm(y_true[:,:,tf.newaxis,:] - pos_sensor, ord='euclidean',\n",
    "                  axis=3,\n",
    "                  keepdims=None,\n",
    "                  name=None,\n",
    "                  keep_dims=None\n",
    "                  )\n",
    "    dist_power = keras.backend.pow(distance, -alpha)\n",
    "    rss_true = keras.backend.sum(dist_power, axis = 1)\n",
    "\n",
    "    distance = tf.norm(y_pred[:,:,tf.newaxis,:] - pos_sensor, ord='euclidean',\n",
    "                  axis=3,\n",
    "                  keepdims=None,\n",
    "                  name=None,\n",
    "                  keep_dims=None\n",
    "                  )\n",
    "    dist_power = keras.backend.pow(distance, -alpha)\n",
    "    rss_pred = keras.backend.sum(dist_power, axis = 1)\n",
    "    \n",
    "    rss_true = keras.backend.log(rss_true) / np.log(log_base)\n",
    "    rss_pred = keras.backend.log(rss_pred) / np.log(log_base)\n",
    "    loss1 = keras.losses.mean_squared_error(rss_true, rss_pred)\n",
    "#     loss = keras.backend.log(loss) / np.log(log_base)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     y_true = tf.transpose(y_true, perm=[0, 2, 1])\n",
    "#     y_pred = tf.transpose(y_pred, perm=[0, 2, 1])        \n",
    "    y_true = tf.reshape(y_true,shape=(-1,N*dim))    \n",
    "    y_pred = tf.reshape(y_pred,shape=(-1,N*dim))    \n",
    "    mse = keras.losses.mean_squared_error(y_true,y_pred)\n",
    "#         perm_mat = np.array([[0,1,0,0],[1,0,0,0],[0,0,0,1],[0,0,1,0]],dtype=np.float32)\n",
    "    if N == 2:\n",
    "        perm_mat = np.array([[0,0,1,0],[0,0,0,1],[1,0,0,0],[0,1,0,0]],dtype=np.float32)        \n",
    "    else:\n",
    "        perm_mat = np.array([[0,1],[1,0]],dtype=np.float32)            \n",
    "        perm_mat = np.array([[1,0],[0,1]],dtype=np.float32)            \n",
    "    y_perm = tf.matmul(y_true,perm_mat)        \n",
    "    mse_perm = keras.losses.mean_squared_error(y_perm,y_pred)            \n",
    "    mse = tf.minimum(mse,mse_perm)    \n",
    "    loss = (1-lam)*loss1 + (lam)*mse\n",
    "    return loss \n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# from itertools import permutations\n",
    "\n",
    "# def myloss(y_true,y_pred):\n",
    "#     y_true = tf.reshape(y_true,shape=(-1,N*dim))    \n",
    "#     y_pred = tf.reshape(y_pred,shape=(-1,N*dim))    \n",
    "#     loss = keras.losses.mean_squared_error(y_true,y_pred)    \n",
    "#     I = indetity_mat(N*dim)\n",
    "#     for m in permutations(I):\n",
    "#         perm_mat = np.array(m,dtype=np.float32)\n",
    "#         y_perm = tf.matmul(y_true,perm_mat)\n",
    "#         loss_tmp = keras.losses.mean_squared_error(y_perm,y_pred)\n",
    "#         loss = tf.minimum(loss,loss_tmp)    \n",
    "#     return loss \n",
    "\n",
    "# def indetity_mat(n):\n",
    "#     I = []\n",
    "#     for i in range(n):\n",
    "#         I.append([1 if j == i else 0 for j in range(n)])\n",
    "#     return I\n",
    "\n",
    "\n",
    "X = X.reshape(X.shape[0],-1,1)\n",
    "model = build_model(X,K,N,dim)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "optimizer = keras.optimizers.Adam(lr=learn_rate, beta_1=beta1_val, beta_2=beta2_val, epsilon=None, decay=decay_val, amsgrad=True)\n",
    "# optimizer =  keras.optimizers.SGD(lr=1e-3, clipnorm=1.)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "model.compile(loss=myloss,optimizer=optimizer,metrics=['mean_squared_error', myloss])\n",
    "# model.compile(loss='mean_squared_error',optimizer=optimizer,metrics=['mean_squared_error',myloss])\n",
    "\n",
    "\n",
    "#print(clf.summary())\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=0, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.0001)]\n",
    "callbacks = []\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(X,Y,epochs=EPOCHS, validation_split = 0.1, verbose=1, callbacks = callbacks)\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"elapsed time: \"+str(elapsed)+\" sec\")\n",
    "\n",
    "## serialize model to JSON\n",
    "#model_json = model.to_json()\n",
    "#with open(\"model.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "## serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "#print(\"Saved model to disk\")\n",
    "\n",
    "pickle.dump([scaler_X,scaler_Y], open(scaler_file, 'wb'))\n",
    "\n",
    "#M = int(1e4)\n",
    "#target_seed = 71212\n",
    "rss_test, pos_target_test, pos_sensor = scenario(N,K,dim,alpha,beta,M,pmax,pmin,w,sensor_seed,target_seed)\n",
    "\n",
    "Xt = rss_transform(rss_test,log_base)\n",
    "if if_x_scale ==True:\n",
    "    Xt = scaler_X.transform(Xt)\n",
    "\n",
    "\n",
    "Xt = Xt.reshape(Xt.shape[0],-1,1)\n",
    "result = model.predict(Xt)\n",
    "result = np.transpose(result, axes=(0,2,1))\n",
    "result = result.reshape(M,N*dim)\n",
    "if if_y_scale == True:\n",
    "    if scaling_type == \"maxmin\":\n",
    "        result = scaler_Y.inverse_transform(result)\n",
    "    elif scaling_type == \"multiply\":\n",
    "            result = result*w\n",
    "            pos_sensor = pos_sensor*w\n",
    "Tx_hat = result[:,:N]\n",
    "Ty_hat = result[:,N:]\n",
    "\n",
    "Yt = np.squeeze(pos_target_test,axis=2)\n",
    "Tx_test = Yt[:,:,0]\n",
    "Ty_test = Yt[:,:,1]\n",
    "MSE = calcMSE(Tx_test.T,Ty_test.T,Tx_hat.T,Ty_hat.T)\n",
    "mse = MSE.reshape(1,-1)[0]\n",
    "print(\"Mean error: \"+str(np.mean(mse)))\n",
    "print(\"Mean error: \"+str(np.var(mse)))\n",
    "for e in [0.1,1,10,100,1000]:\n",
    "  prob=(mse > e).sum()/M*100\n",
    "  print(\"Pr(e>\"+str(e)+\"m)= \"+str(prob)+\"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
