{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 20000\n",
    "set_size = 60000\n",
    "batch_size = 2\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'\n",
    "\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# Data loader\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "#                                          batch_size=batch_size, \n",
    "#                                          shuffle=True)\n",
    "# Download MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "# Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(mnist_dataset))\n",
    "val_size = len(mnist_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n",
    "\n",
    "# Select a random image from the new training set\n",
    "random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "mnist_images = train_dataloader.dataset.dataset.data\n",
    "mnist_labels = train_dataset.dataset.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 20000\n",
    "set_size = 60000\n",
    "batch_size = 2\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'\n",
    "\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# Data loader\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "#                                          batch_size=batch_size, \n",
    "#                                          shuffle=True)\n",
    "# Download MNIST dataset\n",
    "fashion_mnist_dataset = datasets.FashionMNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "# Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(fashion_mnist_dataset))\n",
    "val_size = len(fashion_mnist_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(fashion_mnist_dataset, [train_size, val_size])\n",
    "\n",
    "# Select a random image from the new training set\n",
    "random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "fashion_mnist_images = train_dataloader.dataset.dataset.data\n",
    "fashion_mnist_labels = train_dataset.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                # Convert to tensor\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert RGB to Grayscale\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "\n",
    "# # Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# # Select a random image from the new training set\n",
    "# random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "cifar_images = torch.tensor(train_dataloader.dataset.dataset.data).permute(0, 3, 1, 2)  # Convert to Tensor & Normalize\n",
    "\n",
    "# cifar_images = train_dataloader.dataset.dataset.data\n",
    "cifar_labels = train_dataset.dataset.targets\n",
    "\n",
    "to_grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "cifar_gray = torch.stack([to_grayscale(img) for img in cifar_images]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cdf_mapping(images):\n",
    "    \"\"\"\n",
    "    Compute the CDF mapping for each pixel across all images.\n",
    "    \"\"\"\n",
    "    \n",
    "    vector_size = images.shape[1]\n",
    "    images = images.view(-1, vector_size)  # Flatten images\n",
    "    sorted_pixels, _ = torch.sort(images, dim=0)\n",
    "    cdf = torch.linspace(0, 1, images.shape[0])\n",
    "    pixel_cdf_map = {}\n",
    "    \n",
    "    for i in range(vector_size):\n",
    "        pixel_cdf_map[i] = (sorted_pixels[:, i], cdf)\n",
    "    \n",
    "    return pixel_cdf_map\n",
    "\n",
    "def transform_original_to_uniform(image, pixel_cdf_map, reverse=False):\n",
    "    \"\"\"\n",
    "    Transform an image using the pixel CDF mapping.\n",
    "    \"\"\"\n",
    "    image = image.view(-1)  # Flatten image\n",
    "    transformed_image = torch.zeros_like(image, dtype=torch.float32)\n",
    "    \n",
    "    pixel_size = int(image.shape[0] ** 0.5)\n",
    "    for i in range(pixel_size * pixel_size):\n",
    "        pixel_values, cdf_values = pixel_cdf_map[i]\n",
    "        \n",
    "        if not reverse:\n",
    "            # Forward transformation (find CDF value for each pixel)\n",
    "            indices = torch.searchsorted(pixel_values, image[i])\n",
    "            transformed_image[i] = cdf_values[min(indices, len(cdf_values) - 1)]\n",
    "        else:\n",
    "            # Reverse transformation (find original pixel from CDF value)\n",
    "            indices = torch.searchsorted(cdf_values, image[i])\n",
    "            transformed_image[i] = pixel_values[min(indices, len(pixel_values) - 1)]\n",
    "    \n",
    "    transformed_image = transformed_image.view(pixel_size, pixel_size)  # Reshape back to image size\n",
    "    return transformed_image\n",
    "\n",
    "def compute_mean_and_covariance_in_data_space(images, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix of the dataset, ensuring it is positive definite.\n",
    "    \"\"\"\n",
    "    images = images.float()  # Ensure floating-point type\n",
    "    images = images.view(images.shape[0], -1)  # Flatten images\n",
    "    mean_vector = torch.mean(images, dim=0, keepdim=True)\n",
    "    centered_images = images - mean_vector\n",
    "    covariance_matrix = torch.matmul(centered_images.T, centered_images) / (images.shape[0] - 1)\n",
    "    \n",
    "    # Regularization: Add a small identity matrix to ensure positive definiteness\n",
    "    covariance_matrix += epsilon * torch.eye(covariance_matrix.shape[0])\n",
    "    \n",
    "    return covariance_matrix, mean_vector\n",
    "\n",
    "def compute_covariance_in_uniform_sapce(training_data, epsilon = 1e-5):\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix Σ_u of uniforms obtained by applying marginal CDFs to a dataset of shape (n, d, d).\n",
    "    \n",
    "    Args:\n",
    "        training_data (torch.Tensor): Input tensor of shape (n, d, d), where:\n",
    "            - n: Number of samples\n",
    "            - d: Number of pixels per dimension\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Covariance matrix Σ_u of shape (d*d, d*d) for the uniforms.\n",
    "    \"\"\"\n",
    "    n, d, _ = training_data.shape\n",
    "    \n",
    "    # Flatten the images into vectors: shape (n, d*d)\n",
    "    flattened = training_data.view(n, -1)  # (n, d^2)\n",
    "    \n",
    "    # Compute ranks for each pixel across samples\n",
    "    ranks = torch.argsort(torch.argsort(flattened, dim=0), dim=0)  # (n, d^2)\n",
    "    \n",
    "    # Convert ranks to uniforms using (rank + 1)/(n + 1)\n",
    "    uniforms = (ranks.float() + 1.0) / (n + 1.0)  # (n, d^2)\n",
    "    \n",
    "    # Center the uniforms (mean of U(0,1) is 0.5)\n",
    "    centered = uniforms - 0.5  # (n, d^2)\n",
    "    \n",
    "    # Compute covariance matrix (unbiased estimator)\n",
    "    covariance_matrix_unifrom = torch.matmul(centered.T, centered) / (n - 1)  # (d^2, d^2)\n",
    "    \n",
    "    return covariance_matrix_unifrom + epsilon*torch.eye(covariance_matrix_unifrom.shape[0])\n",
    "\n",
    "def generate_random_uniform_images_from_gaussian(covariance_matrix_gaussian, num_samples = 1):\n",
    "    vector_size = covariance_matrix_gaussian.size(0)\n",
    "    num_pixels = int(vector_size**0.5)\n",
    "    mean = torch.zeros(vector_size, device=covariance_matrix_gaussian.device)\n",
    "    \n",
    "    # Create the multivariate normal distribution\n",
    "    mvn = torch.distributions.MultivariateNormal(\n",
    "        loc=mean,\n",
    "        covariance_matrix=covariance_matrix_gaussian\n",
    "    )\n",
    "    \n",
    "    # Generate samples\n",
    "    gaussian_samples = mvn.rsample((num_samples,))\n",
    "    uniform_samples = 0.5 * (1 + torch.erf(gaussian_samples / np.sqrt(2)))  # Convert Gaussian to Uniform [0,1]\n",
    "    return uniform_samples.reshape(num_samples, num_pixels, num_pixels)\n",
    "\n",
    "\n",
    "def generate_random_uniform_images(covariance_matrix, num_samples = 1):\n",
    "    \"\"\"\n",
    "    Generate samples from a multivariate normal distribution with mean 0 and given covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        covariance_matrix (torch.Tensor): Covariance matrix of shape (num_pixels, num_pixels).\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of shape (num_samples, num_pixels) containing the samples.\n",
    "    \"\"\"\n",
    "    vector_size = covariance_matrix.size(0)\n",
    "    num_pixels = int(vector_size**0.5)\n",
    "    mean = torch.zeros(vector_size, device=covariance_matrix.device)\n",
    "    \n",
    "    # Create the multivariate normal distribution\n",
    "    mvn = torch.distributions.MultivariateNormal(\n",
    "        loc=mean,\n",
    "        covariance_matrix=covariance_matrix\n",
    "    )\n",
    "    \n",
    "    # Generate samples\n",
    "    gaussian_samples = mvn.rsample((num_samples,))\n",
    "    uniform_samples = 0.5 * (1 + torch.erf(gaussian_samples / np.sqrt(2)))  # Convert Gaussian to Uniform [0,1]\n",
    "    return uniform_samples.reshape(num_samples, num_pixels, num_pixels)\n",
    "\n",
    "def transform_dataset_to_uniform_and_gaussian_vectorized(dataset):\n",
    "    \"\"\"\n",
    "    Transform an entire dataset of images (tensor of shape (n, p, p)) so that for each pixel location,\n",
    "    the empirical distribution of pixel values becomes uniform in [0,1]. Then, using the relation\n",
    "    z = sqrt(2) * erfinv(2u - 1), convert the uniform dataset into a Gaussian distributed dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (torch.Tensor): Tensor of shape (n, p, p)\n",
    "        \n",
    "    Returns:\n",
    "        uniform_dataset (torch.Tensor): Transformed dataset with shape (n, p, p) with values in [0,1].\n",
    "        gaussian_dataset (torch.Tensor): Dataset transformed to be Gaussian distributed.\n",
    "    \"\"\"\n",
    "    n, p, _ = dataset.shape\n",
    "    # Flatten images: shape (n, p*p)\n",
    "    flat_data = dataset.view(n, -1)\n",
    "    \n",
    "    # Compute the rank for each pixel across the dataset via double argsort.\n",
    "    # First argsort sorts the values; the second argsort recovers the rank.\n",
    "    ranks = flat_data.argsort(dim=0).argsort(dim=0).float()\n",
    "    \n",
    "    # Normalize ranks to [0,1]\n",
    "    uniform_flat = ranks / (n - 1)\n",
    "    \n",
    "    # Reshape back to (n, p, p)\n",
    "    uniform_dataset = uniform_flat.view(n, p, p)\n",
    "    \n",
    "    # Convert the uniform dataset to Gaussian distributed data:\n",
    "    # For each pixel, apply: z = sqrt(2) * erfinv(2u - 1)\n",
    "    gaussian_dataset = torch.erfinv(2 * uniform_dataset - 1) * torch.sqrt(torch.tensor(2.0))\n",
    "    \n",
    "    return uniform_dataset, gaussian_dataset\n",
    "\n",
    "\n",
    "# def generate_uniform_iman_conover(covariance_matrix, n_samples=10000):\n",
    "#     \"\"\"\n",
    "#     Generate a sample from a d-dimensional distribution with Uniform(0,1) marginals \n",
    "#     whose covariance is approximately the given covariance_matrix.\n",
    "    \n",
    "#     The method uses the Iman–Conover procedure.\n",
    "    \n",
    "#     Args:\n",
    "#         covariance_matrix (np.ndarray): A d x d target covariance matrix.\n",
    "#             (For Uniform[0,1], the variance is 1/12, so the diagonal of covariance_matrix\n",
    "#             should be about 1/12.)\n",
    "#         n_samples (int): Number of samples to generate for the Iman–Conover adjustment.\n",
    "        \n",
    "#     Returns:\n",
    "#         sample (np.ndarray): A d x 1 column vector drawn from the adjusted Uniform(0,1) distribution.\n",
    "#     \"\"\"\n",
    "#     # Dimension (d) inferred from the covariance matrix\n",
    "#     d = covariance_matrix.shape[0]\n",
    "    \n",
    "#     # For Uniform[0,1], variance = 1/12. So the target correlation matrix is:\n",
    "#     R_target = covariance_matrix * 12.0\n",
    "    \n",
    "#     # Step 1: Generate independent Uniform(0,1) samples: shape (n_samples, d)\n",
    "#     U = np.random.uniform(0, 1, size=(n_samples, d))\n",
    "    \n",
    "#     # Step 2: Standardize each column of U\n",
    "#     U_std = (U - U.mean(axis=0)) / U.std(axis=0, ddof=1)\n",
    "    \n",
    "#     # Compute the empirical correlation matrix of U_std\n",
    "#     R_empirical = np.corrcoef(U_std, rowvar=False)\n",
    "    \n",
    "#     # Step 3: Compute Cholesky factors for the empirical and target correlation matrices\n",
    "#     L_empirical = np.linalg.cholesky(R_empirical)\n",
    "#     L_target = np.linalg.cholesky(R_target)\n",
    "    \n",
    "#     # Step 4: Compute the adjustment matrix\n",
    "#     A = L_target @ np.linalg.inv(L_empirical)\n",
    "    \n",
    "#     # Adjust the standardized samples\n",
    "#     Z = U_std @ A.T\n",
    "    \n",
    "#     # Step 5: For each variable (column), reassign values based on the ranks of Z,\n",
    "#     # so that the marginals remain Uniform(0,1) but the correlation structure is adjusted.\n",
    "#     U_adjusted = np.empty_like(U)\n",
    "#     for j in range(d):\n",
    "#         order = np.argsort(Z[:, j])\n",
    "#         sorted_vals = np.sort(U[:, j])\n",
    "#         U_adjusted[order, j] = sorted_vals\n",
    "    \n",
    "#     # Step 6: Choose one sample (e.g., the first row) and return it as a column vector.\n",
    "#     sample = U_adjusted[0, :].reshape(-1, 1)\n",
    "#     uniform_random_image = torch.tensor(sample).view(-1)\n",
    "#     return uniform_random_image\n",
    "\n",
    "def generate_uniform_from_gaussian(covariance_matrix_uniform, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Generates a column vector of uniform samples with the specified covariance matrix,\n",
    "    using a multivariate Gaussian transformation. Handles PyTorch tensors and allows\n",
    "    diagonal entries close to (but not exactly) 1/12.\n",
    "    \"\"\"\n",
    "    d = covariance_matrix_uniform.size(0)\n",
    "    \n",
    "    # Compute standard deviations for each uniform variable\n",
    "    sigma = torch.sqrt(torch.diag(covariance_matrix_uniform))  # Shape: (d,)\n",
    "    \n",
    "    # Compute correlation matrix for the uniforms\n",
    "    outer_sigma = torch.outer(sigma, sigma)\n",
    "    R_uniform = covariance_matrix_uniform / outer_sigma  # Shape: (d, d)\n",
    "    \n",
    "    # Compute Gaussian correlation matrix using adjusted formula\n",
    "    R_gaussian = 2 * torch.sin((math.pi / 6) * R_uniform)\n",
    "    R_gaussian.fill_diagonal_(1.0)  # Ensure diagonal is exactly 1\n",
    "    \n",
    "    # Cholesky decomposition (requires positive definite matrix)\n",
    "    try:\n",
    "        L = torch.linalg.cholesky(R_gaussian + epsilon*torch.eye(d))\n",
    "    except RuntimeError as e:\n",
    "        raise ValueError(\"Invalid covariance: Resulting Gaussian correlation is not positive definite.\") from e\n",
    "    \n",
    "    # Generate multivariate Gaussian sample\n",
    "    z = torch.randn(d)  # Standard normal sample\n",
    "    gaussian_sample = L @ z  # Shape: (d,)\n",
    "    \n",
    "    # Transform Gaussian to uniform using CDF\n",
    "    uniform_sample = 0.5 * (1 + torch.erf(gaussian_sample / math.sqrt(2)))  # Shape: (d,)\n",
    "    \n",
    "    # Scale to match desired covariance (adjust variances and covariances)\n",
    "    scale_factor = torch.sqrt(12 * torch.diag(covariance_matrix_uniform))\n",
    "    scaled_uniform = uniform_sample * scale_factor + 0.5 * (1 - scale_factor)\n",
    "    \n",
    "    return scaled_uniform.reshape(-1, 1)  # Return as column vector\n",
    "def compute_gaussian_covariance_from_uniform(covariance_matrix_unifrom, epsilon = 1e-4):\n",
    "    \"\"\"\n",
    "    Compute the Gaussian covariance matrix from the uniform covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "        covariance_matrix_unifrom (torch.Tensor): Covariance matrix of the uniforms, shape (d, d).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Gaussian covariance matrix, shape (d, d).\n",
    "    \"\"\"\n",
    "    # Compute Pearson correlation matrix of the uniforms\n",
    "    diag_var_u = torch.diag(covariance_matrix_unifrom)  # Variances of uniforms (should be ~1/12)\n",
    "    std_u = torch.sqrt(diag_var_u)    # Standard deviations of uniforms\n",
    "    outer_std = torch.outer(std_u, std_u)\n",
    "    R_u = covariance_matrix_unifrom / outer_std         # Pearson correlation matrix of uniforms\n",
    "\n",
    "    # Compute Gaussian correlation matrix\n",
    "    R_n = 2 * torch.sin((math.pi / 6) * R_u)\n",
    "\n",
    "    # Ensure diagonal is exactly 1 (due to numerical precision)\n",
    "    R_n.fill_diagonal_(1.0)\n",
    "    covariance_matrix_gaussian =  R_n + torch.eye(R_u.shape[0])\n",
    "    return covariance_matrix_gaussian\n",
    "\n",
    "def compute_pixel_cdf_map(images, max_pixel_value = 255):\n",
    "    \"\"\"\n",
    "    Compute the empirical CDF for each pixel position across all images.\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): Tensor of shape (num_samples, pixel_size, pixel_size),\n",
    "                               containing grayscale images with integer pixel values (0-255).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (pixel_size**2, 256), where each row contains\n",
    "                      the empirical CDF for a given pixel position.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples, pixel_size, _ = images.shape\n",
    "    # max_pixel_value = images.max()\n",
    "    \n",
    "    # Flatten images along the pixel dimension\n",
    "    images_flat = images.view(num_samples, -1)  # Shape: (num_samples, pixel_size**2)\n",
    "    \n",
    "    # Initialize the CDF map\n",
    "    cdf_map = torch.zeros((images_flat.shape[1], max_pixel_value + 1), device=images.device)\n",
    "    \n",
    "    # Compute the empirical CDF for each pixel location\n",
    "    for i in range(images_flat.shape[1]):\n",
    "        pixel_values = images_flat[:, i]  # All values for a specific pixel position\n",
    "        hist = torch.bincount(pixel_values, minlength=max_pixel_value + 1).float()  # Count occurrences\n",
    "        cdf_map[i] = hist.cumsum(dim=0) / num_samples  # Normalize to get CDF\n",
    "    \n",
    "    return cdf_map\n",
    "import torch\n",
    "\n",
    "def transform_dataset_to_uniform_distribution(images, cdf_map, reverse=False):\n",
    "    \"\"\"\n",
    "    Transform the dataset into a uniform [0,1] dataset using pixel-wise empirical CDF.\n",
    "    If reverse=True, transform back to the original space.\n",
    "\n",
    "    Args:\n",
    "        images (torch.Tensor): Input dataset of shape (num_samples, pixel_size, pixel_size).\n",
    "                               If reverse=False, dtype=torch.uint8; if reverse=True, dtype=torch.float32.\n",
    "        cdf_map (torch.Tensor): Empirical CDF map of shape (pixel_size**2, 256).\n",
    "        reverse (bool): If True, transform back to the original pixel space.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Transformed dataset of the same shape as input.\n",
    "    \"\"\"\n",
    "    num_samples, pixel_size, _ = images.shape\n",
    "    images_flat = images.view(num_samples, -1)  # Flatten for batch processing\n",
    "    cdf_map = cdf_map.to(images.device)  # Ensure cdf_map is on the same device\n",
    "\n",
    "    if not reverse:\n",
    "        # Forward transformation: Map pixel values to uniform [0,1]\n",
    "        images_flat = images_flat.long()  # Convert to long for indexing\n",
    "        transformed_images_flat = cdf_map[torch.arange(images_flat.shape[1], device=images.device).unsqueeze(0), images_flat]\n",
    "        \n",
    "        # Reshape and ensure float output\n",
    "        transformed_images = transformed_images_flat.view(num_samples, pixel_size, pixel_size).to(torch.float32)\n",
    "        # gaussian_images = torch.erfinv(2 * transformed_images - 1) * torch.sqrt(torch.tensor(2.0))\n",
    "        return transformed_images#, gaussian_images\n",
    "\n",
    "    else:\n",
    "        # Reverse transformation: Map uniform values back to pixel space\n",
    "        pixel_positions = torch.arange(cdf_map.shape[0], device=images.device)\n",
    "\n",
    "        # Use `searchsorted` for **each** pixel position separately\n",
    "        transformed_images_flat = torch.stack([\n",
    "            torch.searchsorted(cdf_map[i], images_flat[:, i], right=True) for i in range(cdf_map.shape[0])\n",
    "        ], dim=1).clip(0, 255)  # Shape (num_samples, pixel_size**2)\n",
    "\n",
    "        # Reshape and ensure byte output\n",
    "        transformed_images = transformed_images_flat.view(num_samples, pixel_size, pixel_size).to(torch.uint8)\n",
    "        return transformed_images\n",
    "\n",
    "def plot_histogram_of_data(data: torch.Tensor, bins: int = 50, color: str = 'blue',\n",
    "                     title: str = 'Empirical PDF', xlabel: str = 'Value', \n",
    "                     ylabel: str = 'Density') -> tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Plot the histogram of a flattened tensor (assumed to represent CDF values).\n",
    "\n",
    "    Args:\n",
    "        data: Input tensor of shape (N,) or (batch_size, ...). Will be flattened.\n",
    "        bins: Number of histogram bins.\n",
    "        color: Histogram color.\n",
    "        title: Plot title.\n",
    "        xlabel: x-axis label.\n",
    "        ylabel: y-axis label.\n",
    "\n",
    "    Returns:\n",
    "        Matplotlib figure and axes.\n",
    "    \"\"\"\n",
    "    # Convert to numpy and flatten\n",
    "    data_np = data.flatten().cpu().numpy()  # Handles GPU tensors\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 5), tight_layout=True)\n",
    "    ax.hist(data_np, bins=bins, density=True, alpha=0.6, color=color, label='Empirical PDF')\n",
    "    # ax.axhline(1.0, color='black', linestyle='--', label='Uniform PDF')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.legend()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def min_max_normalization(data):\n",
    "    data = data\n",
    "    return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "def transform_data_to_have_the_true_covariance(input_images, covariance_matrix_true, mean_value = 0):\n",
    "\n",
    "    pixel_size = input_images.shape[-1]\n",
    "    eigenvalues_data, eigenvector_data = torch.linalg.eig(covariance_matrix_true)\n",
    "    eigenvector_data = eigenvector_data.real\n",
    "    eigenvalues_data = eigenvalues_data.real\n",
    "    correction_matrix = torch.matmul(eigenvector_data,torch.diag(eigenvalues_data)**1)\n",
    "    \n",
    "    # print(input_images.min(), input_images.max())\n",
    "    input_images = (input_images -  mean_value)\n",
    "    transformed_images = torch.matmul(correction_matrix.unsqueeze(0), input_images.reshape(-1,pixel_size**2,1)).reshape(-1, pixel_size, pixel_size)\n",
    "\n",
    "    # print(input_images.min(), input_images.max())\n",
    "    return transformed_images\n",
    "\n",
    "    # \"\"\"\n",
    "    # Transforms a batch of input images such that their covariance matches the given real data covariance.\n",
    "\n",
    "    # Args:\n",
    "    #     input_images (torch.Tensor): Fake images sampled from a input distribution (num_samples, p, p).\n",
    "    #     covariance_matrix_true (torch.Tensor): Target covariance matrix of real data (p*p, p*p).\n",
    "\n",
    "    # Returns:\n",
    "    #     torch.Tensor: Transformed input images with the same covariance as real data (num_samples, p, p).\n",
    "    # \"\"\"\n",
    "\n",
    "    # num_samples, pixel_size, _ = input_images.shape\n",
    "    # p2 = pixel_size ** 2  # Flattened pixel count\n",
    "\n",
    "    # # Flatten images\n",
    "    # input_images_flat = input_images.view(num_samples, p2)\n",
    "\n",
    "\n",
    "    # # Compute empirical covariance of input samples\n",
    "    # mean_input = input_images_flat.mean(dim=0, keepdim=True)\n",
    "    # centered_input = input_images_flat - mean_input\n",
    "    # covariance_input = (centered_input.T @ centered_input) / (num_samples - 1)\n",
    "\n",
    "    # # Compute Cholesky decomposition (or Eigen decomposition)\n",
    "    # L_real = torch.linalg.cholesky(covariance_matrix_true)  # L_real @ L_real.T = covariance_matrix_true\n",
    "    # L_input = torch.linalg.cholesky(covariance_input)  # L_input @ L_input.T = covariance_input\n",
    "\n",
    "    # # Compute correction matrix A\n",
    "    # correction_matrix = L_real @ torch.linalg.inv(L_input)\n",
    "\n",
    "    # # Apply correction matrix\n",
    "    # transformed_images_flat = (input_images_flat - mean_input) @ correction_matrix.T\n",
    "    # transformed_images = transformed_images_flat.view(num_samples, pixel_size, pixel_size)\n",
    "\n",
    "    # return transformed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 9\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def generate_uniform_random_cifar_rgb_per_class(label_idx, num_samples = 5000, set_name = 'cifar-rgb', epsilon = 0):\n",
    "    num_bands = 1\n",
    "    if set_name == 'mnist':\n",
    "        images = mnist_images\n",
    "        train_images = mnist_images[mnist_labels == label_idx]\n",
    "        pixel_size = images.shape[2]\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'fashion-mnist':\n",
    "        images = fashion_mnist_images[fashion_mnist_labels == label_idx]\n",
    "        pixel_size = images.shape[2]\n",
    "        train_images = fashion_mnist_images[fashion_mnist_labels == label_idx]\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'cifar-gray':\n",
    "        pixel_size = cifar_images.shape[2]\n",
    "        train_images = cifar_gray[torch.tensor(cifar_labels) == label_idx,:,:].squeeze(dim=1)\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'cifar-rgb':\n",
    "        num_bands = 3\n",
    "        pixel_size = cifar_images.shape[2]\n",
    "        train_images = cifar_images[torch.tensor(cifar_labels) == label_idx,:,:,:] \n",
    "        # train_images = torch.zeros(5000, 3, pixel_size, pixel_size)\n",
    "        # for band_idx in range(num_bands): \n",
    "            # train_images = cifar_images[torch.tensor(cifar_labels) == label_idx,band_idx,:,:].squeeze(dim=1)\n",
    "    else: return [], []\n",
    "    # print(train_images.shape)\n",
    "    num_samples = min(num_samples, train_images.shape[0])\n",
    "    uniform_real_images = torch.zeros(num_samples, num_bands, pixel_size, pixel_size)\n",
    "    uniform_fake_images = torch.zeros(num_samples, num_bands, pixel_size, pixel_size)\n",
    "    covariance_matrix_real_uniform = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    covariance_matrix_real_gaussian = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    covariance_matrix_real_images = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    correction_matrix = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    eigen_vector_data = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    mean_vecotr_data = torch.zeros(num_bands, pixel_size**2)\n",
    "    covariance_matrix_uniform = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    synthetic_image = torch.zeros(num_bands, pixel_size, pixel_size)\n",
    "    # pixel_cdf_map = [0]*num_bands\n",
    "    pixel_cdf_map = torch.zeros(num_bands, pixel_size**2, 256)\n",
    "    synthetic_images = torch.zeros(num_bands, num_samples, pixel_size, pixel_size)\n",
    "    for band_idx in range(num_bands):\n",
    "\n",
    "        pixel_cdf_map[band_idx, :] = compute_pixel_cdf_map(train_images[:, band_idx, :,:].squeeze())\n",
    "        uniform_real_images[:, band_idx, :, :] = transform_dataset_to_uniform_distribution(train_images[:, band_idx, :, :], pixel_cdf_map[band_idx, :], reverse=False)\n",
    "        # uniform_real_images, _ = transform_dataset_to_uniform_and_gaussian_vectorized(train_images)\n",
    "        covariance_matrix_real_images[band_idx, :, :], _ = compute_mean_and_covariance_in_data_space(train_images[:, band_idx, :, :], epsilon=epsilon)\n",
    "        covariance_matrix_real_uniform[band_idx, :, :], _ = compute_mean_and_covariance_in_data_space(uniform_real_images[:, band_idx,: ,:], epsilon=epsilon)\n",
    "        covariance_matrix_real_gaussian[band_idx, :, :] = compute_gaussian_covariance_from_uniform(covariance_matrix_real_uniform[band_idx, :, :], epsilon = epsilon)\n",
    "\n",
    "\n",
    "        # uniform_fake_images = generate_random_uniform_images(covariance_matrix_real_uniform, num_samples = num_samples)\n",
    "        uniform_fake_images[:, band_idx, :, :] = generate_random_uniform_images(covariance_matrix_real_uniform[band_idx, :, :], num_samples = num_samples)\n",
    "        # uniform_fake_images[:, band_idx, :, :] = generate_random_uniform_images_from_gaussian(covariance_matrix_real_gaussian[band_idx, :, :], num_samples= num_samples)\n",
    "        # uniform_fake_images[:, band_idx, :, :] = generate_random_uniform_images(torch.eye(pixel_size**2), num_samples = num_samples)\n",
    "        # uniform_fake_images[:, band_idx, :, :] = torch.rand(num_samples,pixel_size,pixel_size)\n",
    "        # uniform_fake_images[:, band_idx, :, :] = transform_data_to_have_the_true_covariance(uniform_fake_images[:, band_idx, :, :], covariance_matrix_real_uniform[band_idx, :, :])\n",
    "        # uniform_fake_images = (uniform_fake_images - uniform_fake_images.min()) / (uniform_fake_images.max() - uniform_fake_images.min())\n",
    "\n",
    "\n",
    "        synthetic_images[band_idx, :, :, :] = transform_dataset_to_uniform_distribution(uniform_fake_images[:, band_idx, :, :], pixel_cdf_map[band_idx, :], reverse=True)\n",
    "        synthetic_images[band_idx, :, :, :] = transform_data_to_have_the_true_covariance(synthetic_images[band_idx, :, :, :].float(), \n",
    "                                                                                         covariance_matrix_real_images[band_idx, :, :].float(), \n",
    "                                                                                         mean_value = synthetic_images[band_idx,:,:,:].mean(dim=0))\n",
    "        # # print(synthetic_images[band_idx,:,:,:].mean(dim=0).shape)\n",
    "        # print(synthetic_images[band_idx, :, :, :].min(), synthetic_images[band_idx, :, :, :].max())\n",
    "        # synthetic_images[band_idx, :, :, :] = min_max_normalization(synthetic_images[band_idx,:,:,:])\n",
    "\n",
    "    return uniform_real_images, uniform_fake_images, synthetic_images\n",
    " \n",
    "def plot_synthetic_images(synthetic_images, label_idx, set_name = 'cifar-rgb', number_of_rows_and_columns = 10):\n",
    "    num_bands = synthetic_images.shape[0]\n",
    "    pixel_size = synthetic_images.shape[-1]\n",
    "    fig, axs = plt.subplots(number_of_rows_and_columns, number_of_rows_and_columns, figsize=(number_of_rows_and_columns, number_of_rows_and_columns))\n",
    "    idx = -1\n",
    "    synthetic_image = synthetic_images[:,0,:,:]\n",
    "    correction_matrix = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    mean_vecotr_data = torch.zeros(num_bands, pixel_size**2)\n",
    "    for idx_i in range(number_of_rows_and_columns):\n",
    "        for idx_j in range (0, number_of_rows_and_columns):\n",
    "            idx += 1\n",
    "            for band_idx in range(num_bands):\n",
    "                tmp = synthetic_images[band_idx, idx, :, :]\n",
    "                synthetic_image[band_idx, :, :] = tmp\n",
    "\n",
    "            if num_bands == 3:\n",
    "                axs[idx_i,idx_j].imshow(synthetic_image.permute(1,2,0)/255)\n",
    "            else:\n",
    "                axs[idx_i,idx_j].imshow(synthetic_image.permute(1,2,0), cmap='gray')\n",
    "\n",
    "            axs[idx_i,idx_j].set_xticks([])  # Hide x-ticks\n",
    "            axs[idx_i,idx_j].set_yticks([])  # Hide x-ticks\n",
    "    fig.suptitle('Fake ' + set_name + ' images')\n",
    "    plt.savefig('fake-' + set_name + '-class-'+ str(label_idx) +'.pdf')\n",
    "    plt.close(fig)  # Close figure to free memory\n",
    "\n",
    "num_samples = 10000\n",
    "num_classes = 10\n",
    "uniform_cifar_real_images = torch.zeros(num_samples*num_classes, 3, 32, 32)\n",
    "uniform_cifar_fake_images = torch.zeros(num_samples*num_classes, 3, 32, 32)\n",
    "set_name = 'mnist'\n",
    "set_name = 'fashion-mnist'\n",
    "# set_name = 'cifar-rgb'\n",
    "set_name = 'cifar-gray'\n",
    "ifPlot = True\n",
    "# if num_samples <= 100: ifPlot = True\n",
    "for label_idx in range(num_classes): \n",
    "    print(f\"Class: {label_idx}\" , end=\"\\r\")\n",
    "    # uniform_cifar_real_images[label_idx*5000:(1+label_idx)*5000,:,:,:], uniform_cifar_fake_images[label_idx*5000:(1+label_idx)*5000] = generate_uniform_random_cifar_rgb_per_class(label_idx, num_samples, ifPlot = False)\n",
    "    _, _,synthetic_images = generate_uniform_random_cifar_rgb_per_class(label_idx, num_samples = num_samples, set_name = set_name, epsilon = 1e-8)\n",
    "    plot_synthetic_images(synthetic_images, label_idx, set_name=set_name, number_of_rows_and_columns=5)\n",
    "os.system(f\"pdftk fake-{set_name}-class-*.pdf output fake-{set_name}.pdf\")\n",
    "os.system(f\"rm fake-{set_name}*class*\")\n",
    "    # print(tmp1.shape, tmp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D_loss = 0.7396, G_loss = 19.5982\n",
      "Epoch 10: D_loss = 0.6704, G_loss = 10.3492\n",
      "Epoch 20: D_loss = 0.6077, G_loss = 12.8900\n",
      "Epoch 30: D_loss = 0.5587, G_loss = 15.5758\n"
     ]
    }
   ],
   "source": [
    "label_idx = 7\n",
    "epsilon = 1e-8\n",
    "set_name = 'cifar-gray'\n",
    "pixel_size = cifar_images.shape[-1]\n",
    "train_images = cifar_gray[torch.tensor(cifar_labels) == label_idx,:,:].squeeze(dim=1)\n",
    "\n",
    "set_name = 'fashion-mnist'\n",
    "images = fashion_mnist_images[fashion_mnist_labels == label_idx]\n",
    "pixel_size = images.shape[2]\n",
    "train_images = fashion_mnist_images[fashion_mnist_labels == label_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_samples = train_images.shape[0]\n",
    "num_samples = min(num_samples, train_images.shape[0])\n",
    "pixel_cdf_map = compute_pixel_cdf_map(train_images.squeeze())\n",
    "# transformed_images = map_images_using_cdf(train_images.squeeze().reshape(-1,pixel_size,pixel_size), pixel_cdf_map)\n",
    "uniform_real_images = transform_dataset_to_uniform_distribution(train_images, pixel_cdf_map, reverse=False)\n",
    "# uniform_real_images, _ = transform_dataset_to_uniform_and_gaussian_vectorized(train_images)\n",
    "covariance_matrix_real_images, _ = compute_mean_and_covariance_in_data_space(train_images, epsilon=epsilon)\n",
    "covariance_matrix_real_uniform, _ = compute_mean_and_covariance_in_data_space(uniform_real_images, epsilon=epsilon)\n",
    "covariance_matrix_real_gaussian = compute_gaussian_covariance_from_uniform(covariance_matrix_real_uniform, epsilon = epsilon)\n",
    "\n",
    "\n",
    "# uniform_fake_images = generate_random_uniform_images(covariance_matrix_real_uniform, num_samples = num_samples)\n",
    "uniform_fake_images = generate_random_uniform_images(covariance_matrix_real_uniform, num_samples = num_samples)\n",
    "# uniform_fake_images = generate_random_uniform_images_from_gaussian(covariance_matrix_real_gaussian, num_samples= num_samples)\n",
    "# uniform_fake_images = uniform_real_images\n",
    "uniform_fake_images = transform_data_to_have_the_true_covariance(uniform_fake_images, covariance_matrix_real_uniform)\n",
    "# uniform_fake_images = (uniform_fake_images - uniform_fake_images.min()) / (uniform_fake_images.max() - uniform_fake_images.min())\n",
    "\n",
    "# uniform_fake_images = generate_random_uniform_images(torch.eye(pixel_size**2), num_samples = num_samples)\n",
    "# uniform_fake_images = torch.rand(num_samples,pixel_size,pixel_size)\n",
    "\n",
    "# Apply correction matrix\n",
    "uniform_fake_images_corrected = uniform_fake_images\n",
    "# uniform_fake_images_corrected = improve_fake_images_gan(uniform_real_images, uniform_fake_images, num_epochs= 200, lr = 0.001)\n",
    "uniform_fake_images_corrected = min_max_normalization(uniform_fake_images_corrected)\n",
    "# print(uniform_fake_images_corrected-uniform_fake_images)\n",
    "covariance_matrix_fake_uniform, _ = compute_mean_and_covariance_in_data_space(uniform_fake_images, epsilon=epsilon)\n",
    "# plot_histogram_of_data(uniform_fake_images)\n",
    "# print(uniform_fake_images.min(), uniform_fake_images.max())\n",
    "\n",
    "# synthetic_images = transform_dataset_to_uniform_distribution(uniform_fake_images, pixel_cdf_map, reverse=True)\n",
    "# synthetic_images = transform_data_to_have_the_true_covariance(synthetic_images.float(), covariance_matrix_real_images.float())\n",
    "# synthetic_images = 255*min_max_normalization(synthetic_images)\n",
    "\n",
    "\n",
    "\n",
    "covariance_matrix_fake_uniform, _ = compute_mean_and_covariance_in_data_space(uniform_fake_images, epsilon=epsilon)\n",
    "covariance_matrix_fake_uniform_corrected, _ = compute_mean_and_covariance_in_data_space(uniform_fake_images_corrected, epsilon=epsilon)\n",
    "# print((covariance_matrix_real_uniform-covariance_matrix_fake_uniform).norm(), (covariance_matrix_real_uniform-covariance_matrix_fake_uniform_corrected).norm())\n",
    "\n",
    "# covariance_matrix_fake_images, _ = compute_mean_and_covariance_in_data_space(synthetic_images, epsilon=epsilon)\n",
    "# print(torch.norm(covariance_matrix_real_images-covariance_matrix_fake_images))\n",
    "\n",
    "      \n",
    "# plot_histogram_of_data(uniform_real_images)\n",
    "# plot_histogram_of_data(uniform_fake_images)\n",
    "\n",
    "\n",
    "# _ = plot_histogram_of_data(uniform_fake_images_corrected.detach())\n",
    "      \n",
    "    \n",
    "\n",
    "\n",
    "uniform_fake_images_corrected = min_max_normalization(uniform_fake_images_corrected)\n",
    "synthetic_images = transform_dataset_to_uniform_distribution(uniform_fake_images_corrected, pixel_cdf_map, reverse=True)\n",
    "synthetic_images = transform_data_to_have_the_true_covariance(synthetic_images.float(), \n",
    "                                                              covariance_matrix_real_images,\n",
    "                                                              mean_value = synthetic_images.float().mean(dim=0))\n",
    "\n",
    "synthetic_images = 255*min_max_normalization(synthetic_images)\n",
    "synthetic_images = improve_fake_images_gan(train_images, synthetic_images, num_epochs= 500, lr = 0.00005)\n",
    "# print(synthetic_images.min(), synthetic_images.max())\n",
    "\n",
    "plot_synthetic_images(synthetic_images.unsqueeze(0), label_idx, set_name=set_name, number_of_rows_and_columns=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after class definition on line 57 (3577753030.py, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[190], line 70\u001b[0;36m\u001b[0m\n\u001b[0;31m    class Discriminator(nn.Module):\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 57\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the Generator (Neural Network)\n",
    "class Generator(nn.Module):\n",
    "    # def __init__(self, pixel_size):\n",
    "    #     super(Generator, self).__init__()\n",
    "    #     input_size = pixel_size**2\n",
    "    #     self.model = nn.Sequential(\n",
    "    #         nn.Linear(input_size, 512),\n",
    "    #         nn.ReLU(),\n",
    "    #         nn.Linear(512, 1024),\n",
    "    #         nn.ReLU(),\n",
    "    #         nn.Linear(1024, input_size),\n",
    "    #         nn.Tanh()  # Output between [-1, 1]\n",
    "    #     )\n",
    "    def __init__(self, pixel_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input: (noise_dim + 1, 256, 256)\n",
    "            nn.Conv2d(pixel_size**2, 64, 4, 2, 1, bias=False),  # Output: (64, 128, 128)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),  # Output: (128, 64, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),  # Output: (256, 32, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),  # Output: (512, 16, 16)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),  # Output: (1024, 8, 8)\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False),  # Output: (512, 16, 16)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # Output: (256, 32, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # Output: (128, 64, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),  # Output: (64, 128, 128)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),  # Output: (1, 256, 256)\n",
    "            nn.tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)  # Flatten\n",
    "        x = self.model(x)\n",
    "        x = (x + 1) / 2 * 255  # Rescale to [0, 255]\n",
    "        return x.view(-1, pixel_size, pixel_size)  # Reshape to image size\n",
    "        class Generator(nn.Module):\n",
    "\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, pixel_size):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.pixel_size = pixel_size\n",
    "#         self.A = nn.Parameter(torch.eye(pixel_size**2))  # Learnable correction matrix\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return torch.matmul(x, self.A.T).view(num_samples, pixel_size, pixel_size)  # Apply correction matrix\n",
    "\n",
    "# Define the Discriminator (Neural Network)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, pixel_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        input_size = pixel_size**2\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Probability of being real\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)  # Flatten\n",
    "        return self.model(x)\n",
    "\n",
    "# Training function\n",
    "def improve_fake_images_gan(real_images, fake_images, num_epochs=1000, lr=0.0002):\n",
    "    num_samples, pixel_size, _ = real_images.shape\n",
    "\n",
    "    # Flatten images\n",
    "    X = real_images.view(num_samples, -1) / 255  # Normalize to [0,1]\n",
    "    Y = fake_images.view(num_samples, -1) / 255\n",
    "\n",
    "    # Initialize models\n",
    "    G = Generator(pixel_size)\n",
    "    D = Discriminator(pixel_size)\n",
    "\n",
    "    # Optimizers and Loss Function\n",
    "    optimizer_G = optim.Adam(G.parameters(), lr=lr)\n",
    "    optimizer_D = optim.Adam(D.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # === Train Discriminator ===\n",
    "        optimizer_D.zero_grad()\n",
    "        real_labels = torch.ones(num_samples, 1)\n",
    "        fake_labels = torch.zeros(num_samples, 1)\n",
    "\n",
    "        real_loss = criterion(D(X), real_labels)\n",
    "        fake_loss = criterion(D(G(Y).detach()), fake_labels)\n",
    "\n",
    "        D_loss = real_loss + fake_loss\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # === Train Generator ===\n",
    "        optimizer_G.zero_grad()\n",
    "        G_loss = criterion(D(G(Y)), real_labels)  # Fool D\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: D_loss = {D_loss.item():.4f}, G_loss = {G_loss.item():.4f}\")\n",
    "\n",
    "    corrected_fake_images = G(Y)#.clamp(0, 255)  # Ensure valid pixel range\n",
    "    return corrected_fake_images.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
