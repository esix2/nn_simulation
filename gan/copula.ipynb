{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 20000\n",
    "set_size = 60000\n",
    "batch_size = 2\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'\n",
    "\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# Data loader\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "#                                          batch_size=batch_size, \n",
    "#                                          shuffle=True)\n",
    "# Download MNIST dataset\n",
    "mnist_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "# Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(mnist_dataset))\n",
    "val_size = len(mnist_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n",
    "\n",
    "# Select a random image from the new training set\n",
    "random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "mnist_images = train_dataloader.dataset.dataset.data\n",
    "mnist_labels = train_dataset.dataset.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 20000\n",
    "set_size = 60000\n",
    "batch_size = 2\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'\n",
    "\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# Data loader\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "#                                          batch_size=batch_size, \n",
    "#                                          shuffle=True)\n",
    "# Download MNIST dataset\n",
    "fashion_mnist_dataset = datasets.FashionMNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "# Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(fashion_mnist_dataset))\n",
    "val_size = len(fashion_mnist_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(fashion_mnist_dataset, [train_size, val_size])\n",
    "\n",
    "# Select a random image from the new training set\n",
    "random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "fashion_mnist_images = train_dataloader.dataset.dataset.data\n",
    "fashion_mnist_labels = train_dataset.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                # Convert to tensor\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert RGB to Grayscale\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='data', \n",
    "                               train=True, \n",
    "                               transform=transform, \n",
    "                               download=True)\n",
    "\n",
    "# # Split original training set into 70% train and 30% validation\n",
    "train_size = int(0.7 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# # Select a random image from the new training set\n",
    "# random_index = np.random.randint(len(train_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "cifar_images = torch.tensor(train_dataloader.dataset.dataset.data).permute(0, 3, 1, 2)  # Convert to Tensor & Normalize\n",
    "\n",
    "# cifar_images = train_dataloader.dataset.dataset.data\n",
    "cifar_labels = train_dataset.dataset.targets\n",
    "\n",
    "to_grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "cifar_gray = torch.stack([to_grayscale(img) for img in cifar_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cdf_mapping(images):\n",
    "    \"\"\"\n",
    "    Compute the CDF mapping for each pixel across all images.\n",
    "    \"\"\"\n",
    "    \n",
    "    vector_size = images.shape[1]\n",
    "    images = images.view(-1, vector_size)  # Flatten images\n",
    "    sorted_pixels, _ = torch.sort(images, dim=0)\n",
    "    cdf = torch.linspace(0, 1, images.shape[0])\n",
    "    pixel_cdf_map = {}\n",
    "    \n",
    "    for i in range(vector_size):\n",
    "        pixel_cdf_map[i] = (sorted_pixels[:, i], cdf)\n",
    "    \n",
    "    return pixel_cdf_map\n",
    "\n",
    "def transform_original_to_uniform(image, pixel_cdf_map, reverse=False):\n",
    "    \"\"\"\n",
    "    Transform an image using the pixel CDF mapping.\n",
    "    \"\"\"\n",
    "    image = image.view(-1)  # Flatten image\n",
    "    transformed_image = torch.zeros_like(image, dtype=torch.float32)\n",
    "    \n",
    "    pixel_size = int(image.shape[0] ** 0.5)\n",
    "    for i in range(pixel_size * pixel_size):\n",
    "        pixel_values, cdf_values = pixel_cdf_map[i]\n",
    "        \n",
    "        if not reverse:\n",
    "            # Forward transformation (find CDF value for each pixel)\n",
    "            indices = torch.searchsorted(pixel_values, image[i])\n",
    "            transformed_image[i] = cdf_values[min(indices, len(cdf_values) - 1)]\n",
    "        else:\n",
    "            # Reverse transformation (find original pixel from CDF value)\n",
    "            indices = torch.searchsorted(cdf_values, image[i])\n",
    "            transformed_image[i] = pixel_values[min(indices, len(pixel_values) - 1)]\n",
    "    \n",
    "    transformed_image = transformed_image.view(pixel_size, pixel_size)  # Reshape back to image size\n",
    "    return transformed_image\n",
    "\n",
    "def compute_mean_and_covariance_in_data_space(images, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix of the dataset, ensuring it is positive definite.\n",
    "    \"\"\"\n",
    "    images = images.float()  # Ensure floating-point type\n",
    "    images = images.view(images.shape[0], -1)  # Flatten images\n",
    "    mean_vector = torch.mean(images, dim=0, keepdim=True)\n",
    "    centered_images = images - mean_vector\n",
    "    covariance_matrix = torch.matmul(centered_images.T, centered_images) / (images.shape[0] - 1)\n",
    "    \n",
    "    # Regularization: Add a small identity matrix to ensure positive definiteness\n",
    "    covariance_matrix += epsilon * torch.eye(covariance_matrix.shape[0])\n",
    "    \n",
    "    return covariance_matrix, mean_vector\n",
    "\n",
    "def compute_covariance_in_uniform_sapce(training_data, epsilon = 1e-5):\n",
    "    \"\"\"\n",
    "    Compute the covariance matrix Σ_u of uniforms obtained by applying marginal CDFs to a dataset of shape (n, d, d).\n",
    "    \n",
    "    Args:\n",
    "        training_data (torch.Tensor): Input tensor of shape (n, d, d), where:\n",
    "            - n: Number of samples\n",
    "            - d: Number of pixels per dimension\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Covariance matrix Σ_u of shape (d*d, d*d) for the uniforms.\n",
    "    \"\"\"\n",
    "    n, d, _ = training_data.shape\n",
    "    \n",
    "    # Flatten the images into vectors: shape (n, d*d)\n",
    "    flattened = training_data.view(n, -1)  # (n, d^2)\n",
    "    \n",
    "    # Compute ranks for each pixel across samples\n",
    "    ranks = torch.argsort(torch.argsort(flattened, dim=0), dim=0)  # (n, d^2)\n",
    "    \n",
    "    # Convert ranks to uniforms using (rank + 1)/(n + 1)\n",
    "    uniforms = (ranks.float() + 1.0) / (n + 1.0)  # (n, d^2)\n",
    "    \n",
    "    # Center the uniforms (mean of U(0,1) is 0.5)\n",
    "    centered = uniforms - 0.5  # (n, d^2)\n",
    "    \n",
    "    # Compute covariance matrix (unbiased estimator)\n",
    "    covariance_matrix_unifrom = torch.matmul(centered.T, centered) / (n - 1)  # (d^2, d^2)\n",
    "    \n",
    "    return covariance_matrix_unifrom + epsilon*torch.eye(covariance_matrix_unifrom.shape[0])\n",
    "\n",
    "def generate_random_uniform_images_from_gaussian(covariance_matrix_gaussian, num_samples = 1):\n",
    "    vector_size = covariance_matrix_gaussian.size(0)\n",
    "    num_pixels = int(vector_size**0.5)\n",
    "    mean = torch.zeros(vector_size, device=covariance_matrix_gaussian.device)\n",
    "    \n",
    "    # Create the multivariate normal distribution\n",
    "    mvn = torch.distributions.MultivariateNormal(\n",
    "        loc=mean,\n",
    "        covariance_matrix=covariance_matrix_gaussian\n",
    "    )\n",
    "    \n",
    "    # Generate samples\n",
    "    gaussian_samples = mvn.rsample((num_samples,))\n",
    "    uniform_samples = 0.5 * (1 + torch.erf(gaussian_samples / np.sqrt(2)))  # Convert Gaussian to Uniform [0,1]\n",
    "    return uniform_samples.reshape(num_samples, num_pixels, num_pixels)\n",
    "\n",
    "\n",
    "def generate_random_uniform_images(covariance_matrix, num_samples = 1):\n",
    "    \"\"\"\n",
    "    Generate samples from a multivariate normal distribution with mean 0 and given covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "        num_samples (int): Number of samples to generate.\n",
    "        covariance_matrix (torch.Tensor): Covariance matrix of shape (num_pixels, num_pixels).\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of shape (num_samples, num_pixels) containing the samples.\n",
    "    \"\"\"\n",
    "    vector_size = covariance_matrix.size(0)\n",
    "    num_pixels = int(vector_size**0.5)\n",
    "    mean = torch.zeros(vector_size, device=covariance_matrix.device)\n",
    "    \n",
    "    # Create the multivariate normal distribution\n",
    "    mvn = torch.distributions.MultivariateNormal(\n",
    "        loc=mean,\n",
    "        covariance_matrix=covariance_matrix\n",
    "    )\n",
    "    \n",
    "    # Generate samples\n",
    "    gaussian_samples = mvn.rsample((num_samples,))\n",
    "    uniform_samples = 0.5 * (1 + torch.erf(gaussian_samples / np.sqrt(2)))  # Convert Gaussian to Uniform [0,1]\n",
    "    return uniform_samples.reshape(num_samples, num_pixels, num_pixels)\n",
    "\n",
    "def transform_dataset_to_uniform_and_gaussian_vectorized(dataset):\n",
    "    \"\"\"\n",
    "    Transform an entire dataset of images (tensor of shape (n, p, p)) so that for each pixel location,\n",
    "    the empirical distribution of pixel values becomes uniform in [0,1]. Then, using the relation\n",
    "    z = sqrt(2) * erfinv(2u - 1), convert the uniform dataset into a Gaussian distributed dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (torch.Tensor): Tensor of shape (n, p, p)\n",
    "        \n",
    "    Returns:\n",
    "        uniform_dataset (torch.Tensor): Transformed dataset with shape (n, p, p) with values in [0,1].\n",
    "        gaussian_dataset (torch.Tensor): Dataset transformed to be Gaussian distributed.\n",
    "    \"\"\"\n",
    "    n, p, _ = dataset.shape\n",
    "    # Flatten images: shape (n, p*p)\n",
    "    flat_data = dataset.view(n, -1)\n",
    "    \n",
    "    # Compute the rank for each pixel across the dataset via double argsort.\n",
    "    # First argsort sorts the values; the second argsort recovers the rank.\n",
    "    ranks = flat_data.argsort(dim=0).argsort(dim=0).float()\n",
    "    \n",
    "    # Normalize ranks to [0,1]\n",
    "    uniform_flat = ranks / (n - 1)\n",
    "    \n",
    "    # Reshape back to (n, p, p)\n",
    "    uniform_dataset = uniform_flat.view(n, p, p)\n",
    "    \n",
    "    # Convert the uniform dataset to Gaussian distributed data:\n",
    "    # For each pixel, apply: z = sqrt(2) * erfinv(2u - 1)\n",
    "    gaussian_dataset = torch.erfinv(2 * uniform_dataset - 1) * torch.sqrt(torch.tensor(2.0))\n",
    "    \n",
    "    return uniform_dataset, gaussian_dataset\n",
    "\n",
    "\n",
    "# def generate_uniform_iman_conover(covariance_matrix, n_samples=10000):\n",
    "#     \"\"\"\n",
    "#     Generate a sample from a d-dimensional distribution with Uniform(0,1) marginals \n",
    "#     whose covariance is approximately the given covariance_matrix.\n",
    "    \n",
    "#     The method uses the Iman–Conover procedure.\n",
    "    \n",
    "#     Args:\n",
    "#         covariance_matrix (np.ndarray): A d x d target covariance matrix.\n",
    "#             (For Uniform[0,1], the variance is 1/12, so the diagonal of covariance_matrix\n",
    "#             should be about 1/12.)\n",
    "#         n_samples (int): Number of samples to generate for the Iman–Conover adjustment.\n",
    "        \n",
    "#     Returns:\n",
    "#         sample (np.ndarray): A d x 1 column vector drawn from the adjusted Uniform(0,1) distribution.\n",
    "#     \"\"\"\n",
    "#     # Dimension (d) inferred from the covariance matrix\n",
    "#     d = covariance_matrix.shape[0]\n",
    "    \n",
    "#     # For Uniform[0,1], variance = 1/12. So the target correlation matrix is:\n",
    "#     R_target = covariance_matrix * 12.0\n",
    "    \n",
    "#     # Step 1: Generate independent Uniform(0,1) samples: shape (n_samples, d)\n",
    "#     U = np.random.uniform(0, 1, size=(n_samples, d))\n",
    "    \n",
    "#     # Step 2: Standardize each column of U\n",
    "#     U_std = (U - U.mean(axis=0)) / U.std(axis=0, ddof=1)\n",
    "    \n",
    "#     # Compute the empirical correlation matrix of U_std\n",
    "#     R_empirical = np.corrcoef(U_std, rowvar=False)\n",
    "    \n",
    "#     # Step 3: Compute Cholesky factors for the empirical and target correlation matrices\n",
    "#     L_empirical = np.linalg.cholesky(R_empirical)\n",
    "#     L_target = np.linalg.cholesky(R_target)\n",
    "    \n",
    "#     # Step 4: Compute the adjustment matrix\n",
    "#     A = L_target @ np.linalg.inv(L_empirical)\n",
    "    \n",
    "#     # Adjust the standardized samples\n",
    "#     Z = U_std @ A.T\n",
    "    \n",
    "#     # Step 5: For each variable (column), reassign values based on the ranks of Z,\n",
    "#     # so that the marginals remain Uniform(0,1) but the correlation structure is adjusted.\n",
    "#     U_adjusted = np.empty_like(U)\n",
    "#     for j in range(d):\n",
    "#         order = np.argsort(Z[:, j])\n",
    "#         sorted_vals = np.sort(U[:, j])\n",
    "#         U_adjusted[order, j] = sorted_vals\n",
    "    \n",
    "#     # Step 6: Choose one sample (e.g., the first row) and return it as a column vector.\n",
    "#     sample = U_adjusted[0, :].reshape(-1, 1)\n",
    "#     uniform_random_image = torch.tensor(sample).view(-1)\n",
    "#     return uniform_random_image\n",
    "\n",
    "# def generate_uniform_from_gaussian(covariance_matrix_uniform, epsilon=1e-4):\n",
    "#     \"\"\"\n",
    "#     Generates a column vector of uniform samples with the specified covariance matrix,\n",
    "#     using a multivariate Gaussian transformation. Handles PyTorch tensors and allows\n",
    "#     diagonal entries close to (but not exactly) 1/12.\n",
    "#     \"\"\"\n",
    "#     d = covariance_matrix_uniform.size(0)\n",
    "    \n",
    "#     # Compute standard deviations for each uniform variable\n",
    "#     sigma = torch.sqrt(torch.diag(covariance_matrix_uniform))  # Shape: (d,)\n",
    "    \n",
    "#     # Compute correlation matrix for the uniforms\n",
    "#     outer_sigma = torch.outer(sigma, sigma)\n",
    "#     R_uniform = covariance_matrix_uniform / outer_sigma  # Shape: (d, d)\n",
    "    \n",
    "#     # Compute Gaussian correlation matrix using adjusted formula\n",
    "#     R_gaussian = 2 * torch.sin((math.pi / 6) * R_uniform)\n",
    "#     R_gaussian.fill_diagonal_(1.0)  # Ensure diagonal is exactly 1\n",
    "    \n",
    "#     # Cholesky decomposition (requires positive definite matrix)\n",
    "#     try:\n",
    "#         L = torch.linalg.cholesky(R_gaussian + epsilon*torch.eye(d))\n",
    "#     except RuntimeError as e:\n",
    "#         raise ValueError(\"Invalid covariance: Resulting Gaussian correlation is not positive definite.\") from e\n",
    "    \n",
    "#     # Generate multivariate Gaussian sample\n",
    "#     z = torch.randn(d)  # Standard normal sample\n",
    "#     gaussian_sample = L @ z  # Shape: (d,)\n",
    "    \n",
    "#     # Transform Gaussian to uniform using CDF\n",
    "#     uniform_sample = 0.5 * (1 + torch.erf(gaussian_sample / math.sqrt(2)))  # Shape: (d,)\n",
    "    \n",
    "#     # Scale to match desired covariance (adjust variances and covariances)\n",
    "#     scale_factor = torch.sqrt(12 * torch.diag(covariance_matrix_uniform))\n",
    "#     scaled_uniform = uniform_sample * scale_factor + 0.5 * (1 - scale_factor)\n",
    "    \n",
    "#     return scaled_uniform.reshape(-1, 1)  # Return as column vector\n",
    "def compute_gaussian_covariance_from_uniform(covariance_matrix_unifrom, epsilon = 1e-4):\n",
    "    \"\"\"\n",
    "    Compute the Gaussian covariance matrix from the uniform covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "        covariance_matrix_unifrom (torch.Tensor): Covariance matrix of the uniforms, shape (d, d).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Gaussian covariance matrix, shape (d, d).\n",
    "    \"\"\"\n",
    "    # Compute Pearson correlation matrix of the uniforms\n",
    "    diag_var_u = torch.diag(covariance_matrix_unifrom)  # Variances of uniforms (should be ~1/12)\n",
    "    std_u = torch.sqrt(diag_var_u)    # Standard deviations of uniforms\n",
    "    outer_std = torch.outer(std_u, std_u)\n",
    "    R_u = covariance_matrix_unifrom / outer_std         # Pearson correlation matrix of uniforms\n",
    "\n",
    "    # Compute Gaussian correlation matrix\n",
    "    R_n = 2 * torch.sin((math.pi / 6) * R_u)\n",
    "\n",
    "    # Ensure diagonal is exactly 1 (due to numerical precision)\n",
    "    R_n.fill_diagonal_(1.0)\n",
    "    covariance_matrix_gaussian =  R_n + torch.eye(R_u.shape[0])\n",
    "    return covariance_matrix_gaussian\n",
    "\n",
    "def compute_pixel_cdf_map(images, max_pixel_value = 255):\n",
    "    \"\"\"\n",
    "    Compute the empirical CDF for each pixel position across all images.\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): Tensor of shape (num_samples, pixel_size, pixel_size),\n",
    "                               containing grayscale images with integer pixel values (0-255).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (pixel_size**2, 256), where each row contains\n",
    "                      the empirical CDF for a given pixel position.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples, pixel_size, _ = images.shape\n",
    "    # max_pixel_value = images.max()\n",
    "    \n",
    "    # Flatten images along the pixel dimension\n",
    "    images_flat = images.view(num_samples, -1)  # Shape: (num_samples, pixel_size**2)\n",
    "    \n",
    "    # Initialize the CDF map\n",
    "    cdf_map = torch.zeros((images_flat.shape[1], max_pixel_value + 1), device=images.device)\n",
    "    \n",
    "    # Compute the empirical CDF for each pixel location\n",
    "    for i in range(images_flat.shape[1]):\n",
    "        pixel_values = images_flat[:, i]  # All values for a specific pixel position\n",
    "        hist = torch.bincount(pixel_values, minlength=max_pixel_value + 1).float()  # Count occurrences\n",
    "        cdf_map[i] = hist.cumsum(dim=0) / num_samples  # Normalize to get CDF\n",
    "    \n",
    "    return cdf_map\n",
    "import torch\n",
    "\n",
    "def transform_dataset_to_uniform_new(images, cdf_map, reverse=False):\n",
    "    \"\"\"\n",
    "    Transform the dataset into a uniform [0,1] dataset using pixel-wise empirical CDF.\n",
    "    If reverse=True, transform back to the original space.\n",
    "\n",
    "    Args:\n",
    "        images (torch.Tensor): Input dataset of shape (num_samples, pixel_size, pixel_size).\n",
    "                               If reverse=False, dtype=torch.uint8; if reverse=True, dtype=torch.float32.\n",
    "        cdf_map (torch.Tensor): Empirical CDF map of shape (pixel_size**2, 256).\n",
    "        reverse (bool): If True, transform back to the original pixel space.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Transformed dataset of the same shape as input.\n",
    "    \"\"\"\n",
    "    num_samples, pixel_size, _ = images.shape\n",
    "    images_flat = images.view(num_samples, -1)  # Flatten for batch processing\n",
    "    cdf_map = cdf_map.to(images.device)  # Ensure cdf_map is on the same device\n",
    "\n",
    "    if not reverse:\n",
    "        # Forward transformation: Map pixel values to uniform [0,1]\n",
    "        images_flat = images_flat.long()  # Convert to long for indexing\n",
    "        transformed_images_flat = cdf_map[torch.arange(images_flat.shape[1], device=images.device).unsqueeze(0), images_flat]\n",
    "        \n",
    "        # Reshape and ensure float output\n",
    "        transformed_images = transformed_images_flat.view(num_samples, pixel_size, pixel_size).to(torch.float32)\n",
    "        return transformed_images\n",
    "\n",
    "    else:\n",
    "        # Reverse transformation: Map uniform values back to pixel space\n",
    "        pixel_positions = torch.arange(cdf_map.shape[0], device=images.device)\n",
    "\n",
    "        # Use `searchsorted` for **each** pixel position separately\n",
    "        transformed_images_flat = torch.stack([\n",
    "            torch.searchsorted(cdf_map[i], images_flat[:, i], right=True) for i in range(cdf_map.shape[0])\n",
    "        ], dim=1).clip(0, 255)  # Shape (num_samples, pixel_size**2)\n",
    "\n",
    "        # Reshape and ensure byte output\n",
    "        transformed_images = transformed_images_flat.view(num_samples, pixel_size, pixel_size).to(torch.uint8)\n",
    "        return transformed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def generate_uniform_random_cifar_rgb_per_class(label_idx, num_samples = 5000, set_name = 'cifar-rgb'):\n",
    "    num_bands = 1\n",
    "    if set_name == 'mnist':\n",
    "        images = mnist_images\n",
    "        train_images = mnist_images[mnist_labels == label_idx]\n",
    "        pixel_size = images.shape[2]\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'fashion-mnist':\n",
    "        images = fashion_mnist_images[fashion_mnist_labels == label_idx]\n",
    "        pixel_size = images.shape[2]\n",
    "        train_images = fashion_mnist_images[fashion_mnist_labels == label_idx]\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'cifar-gray':\n",
    "        pixel_size = cifar_images.shape[2]\n",
    "        train_images = cifar_gray[torch.tensor(cifar_labels) == label_idx,:,:].squeeze(dim=1)\n",
    "        train_images = train_images.unsqueeze(1)\n",
    "    elif set_name == 'cifar-rgb':\n",
    "        num_bands = 3\n",
    "        pixel_size = cifar_images.shape[2]\n",
    "        train_images = cifar_images[torch.tensor(cifar_labels) == label_idx,:,:,:]\n",
    "        # train_images = torch.zeros(5000, 3, pixel_size, pixel_size)\n",
    "        # for band_idx in range(num_bands): \n",
    "            # train_images = cifar_images[torch.tensor(cifar_labels) == label_idx,band_idx,:,:].squeeze(dim=1)\n",
    "    else: return [], []\n",
    "    # print(train_images.shape)\n",
    "    num_samples = min(num_samples, train_images.shape[0])\n",
    "    uniform_real_images = torch.zeros(num_samples, num_bands, pixel_size, pixel_size)\n",
    "    uniform_fake_images = torch.zeros(num_samples, num_bands, pixel_size, pixel_size)\n",
    "    covariance_matrix_data = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    correction_matrix = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    eigen_vector_data = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    mean_vecotr_data = torch.zeros(num_bands, pixel_size**2)\n",
    "    covariance_matrix_uniform = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    synthetic_image = torch.zeros(num_bands, pixel_size, pixel_size)\n",
    "    # pixel_cdf_map = [0]*num_bands\n",
    "    pixel_cdf_map = torch.zeros(num_bands, pixel_size**2, 256)\n",
    "    synthetic_images = torch.zeros(num_bands, num_samples, pixel_size, pixel_size)\n",
    "    for band_idx in range(num_bands):\n",
    "        # pixel_cdf_map[band_idx] = compute_cdf_mapping(train_images[:,band_idx,:,:].reshape(-1, pixel_size**2))\n",
    "        # print(pixel_cdf_map.shape)\n",
    "        pixel_cdf_map[band_idx, :] = compute_pixel_cdf_map(train_images[:, band_idx, :,:].squeeze())\n",
    "        # transformed_images = map_images_using_cdf(train_images[:, band_idx, :, :].squeeze().reshape(-1,pixel_size,pixel_size), pixel_cdf_map[band_idx, :])\n",
    "        uniform_real_images[:, band_idx, :, :] = transform_dataset_to_uniform_new(train_images[:, band_idx, :, :], pixel_cdf_map[band_idx,:], reverse=False)\n",
    "        # uniform_real_images[:, band_idx, :, :], _ = transform_dataset_to_uniform_and_gaussian_vectorized(train_images[0:num_samples,band_idx,:,:])\n",
    "        covariance_matrix_data[band_idx, :, :], mean_vecotr_data[band_idx, :] = compute_mean_and_covariance_in_data_space(uniform_real_images[:,band_idx,:,:], epsilon=1e-8)\n",
    "        \n",
    "        uniform_fake_images[:, band_idx,:,:] = generate_random_uniform_images(covariance_matrix_data[band_idx, :, :], num_samples = num_samples)\n",
    "        # uniform_fake_images[:, band_idx,:,:] = generate_random_uniform_images(1/12*torch.eye(pixel_size**2), num_samples = num_samples)\n",
    "        synthetic_images[band_idx, :, :, :] = transform_dataset_to_uniform_new(uniform_fake_images[:,band_idx, :, :], pixel_cdf_map[band_idx, :], reverse=True)\n",
    "\n",
    "        # covariance_matrix_uniform[band_idx, :, :] = compute_covariance_in_uniform_sapce(train_images[:,band_idx,:,:].squeeze(), epsilon=1e-5)\n",
    "        # uniform_fake_images[:, band_idx,:,:] = generate_random_uniform_images(covariance_matrix_uniform[band_idx,:,:], num_samples = num_samples)\n",
    "        \n",
    "        # covariance_matrix_gaussian = compute_gaussian_covariance_from_uniform(covariance_matrix_uniform, epsilon = 1e-6) \n",
    "        # uniform_fake_images[:, band_idx,:,:] = generate_random_uniform_images_from_gaussian(torch.eye(covariance_matrix_data.shape[0]))\n",
    "    return uniform_real_images, uniform_fake_images, synthetic_images\n",
    " \n",
    "def plot_synthetic_images(synthetic_images, label_idx, set_name = 'cifar-rgb', number_of_rows_and_columns = 10):\n",
    "    num_bands = synthetic_images.shape[0]\n",
    "    pixel_size = synthetic_images.shape[-1]\n",
    "    fig, axs = plt.subplots(number_of_rows_and_columns, number_of_rows_and_columns, figsize=(number_of_rows_and_columns, number_of_rows_and_columns))\n",
    "    idx = -1\n",
    "    synthetic_image = synthetic_images[:,0,:,:]\n",
    "    correction_matrix = torch.zeros(num_bands, pixel_size**2, pixel_size**2)\n",
    "    mean_vecotr_data = torch.zeros(num_bands, pixel_size**2)\n",
    "    for band_idx in range(num_bands):\n",
    "        covariance_matrix_data, mean_vecotr_data[band_idx, :] = compute_mean_and_covariance_in_data_space(synthetic_images[band_idx,:,:,:])\n",
    "        eigenvalues_data, eigenvector_data = torch.linalg.eig(covariance_matrix_data)\n",
    "        eigenvector_data = eigenvector_data.real\n",
    "        eigenvalues_data = eigenvalues_data.real\n",
    "        correction_matrix[band_idx] = torch.matmul(eigenvector_data,torch.diag(eigenvalues_data))\n",
    "        # correction_matrix[band_idx] = eigenvector_data.T\n",
    "\n",
    "        # correction_matrix[band_idx] = covariance_matrix_data.T\n",
    "        # correction_matrix[band_idx] =  torch.tensor(sqrtm(covariance_matrix_data))\n",
    "    for idx_i in range(number_of_rows_and_columns):\n",
    "        for idx_j in range (0, number_of_rows_and_columns):\n",
    "            idx += 1\n",
    "            # print(f\"Class: {label_idx}, image {idx+1}/{number_of_rows_and_columns**2}\" , end=\"\\r\")\n",
    "            # uniform_random_image = generate_uniform_iman_conover(covariance_matrix_uniform, n_samples=2000)\n",
    "            # uniform_random_image =  generate_uniform_from_gaussian(covariance_matrix_uniform, epsilon=0.0001)\n",
    "            # uniform_random_image, gaussian_random_image = generate_random_image(covariance_matrix_uniform)\n",
    "            for band_idx in range(num_bands):\n",
    "                tmp = synthetic_images[band_idx, idx, :, :]\n",
    "                \n",
    "                # print(tmp.min(), tmp.max())\n",
    "                # tmp = (tmp -  mean_vecotr_data[band_idx,:].reshape(pixel_size,pixel_size))\n",
    "                tmp = torch.matmul(correction_matrix, tmp.reshape(-1,1)).reshape(pixel_size, pixel_size)\n",
    "                tmp = 255*(tmp - tmp.min()) / (tmp.max() - tmp.min())\n",
    "                # print(tmp.min(), tmp.max())\n",
    "                synthetic_image[band_idx, :, :] = tmp\n",
    "\n",
    "            # _, gaussian_random_image = generate_random_image(covariance_matrix_gaussian, 0*mean_uniform)\n",
    "            # uniform_image_from_gaussian = transform_uniform_to_gaussian(gaussian_random_image, reverse=True)\n",
    "            # synthetic_image  = transform_original_to_uniform(uniform_image_from_gaussian, pixel_cdf_map, reverse=True)\n",
    "\n",
    "            if num_bands == 3:\n",
    "                axs[idx_i,idx_j].imshow(synthetic_image.permute(1,2,0))\n",
    "            else:\n",
    "                axs[idx_i,idx_j].imshow(synthetic_image.permute(1,2,0), cmap='gray')\n",
    "            # axs[idx_i,idx_j].imshow(cifar_images[np.random.randint(cifar_images.shape[0]),:,:].permute(1,2,0))\n",
    "\n",
    "            # axs[idx_i,idx_j].set_title('Uniform', fontsize=10)\n",
    "            axs[idx_i,idx_j].set_xticks([])  # Hide x-ticks\n",
    "            axs[idx_i,idx_j].set_yticks([])  # Hide x-ticks\n",
    "    fig.suptitle('Fake ' + set_name + ' images')\n",
    "    plt.savefig('fake-' + set_name + '-class-'+ str(label_idx) +'.pdf')\n",
    "    plt.close(fig)  # Close figure to free memory\n",
    "\n",
    "num_samples = 5000\n",
    "num_classes = 10\n",
    "uniform_cifar_real_images = torch.zeros(num_samples*num_classes, 3, 32, 32)\n",
    "uniform_cifar_fake_images = torch.zeros(num_samples*num_classes, 3, 32, 32)\n",
    "set_name = 'mnist'\n",
    "# set_name = 'fashion-mnist'\n",
    "# set_name = 'cifar-rgb'\n",
    "set_name = 'cifar-gray'\n",
    "ifPlot = True\n",
    "# if num_samples <= 100: ifPlot = True\n",
    "for label_idx in range(num_classes): \n",
    "    print(f\"Class: {label_idx}\" , end=\"\\r\")\n",
    "    # uniform_cifar_real_images[label_idx*5000:(1+label_idx)*5000,:,:,:], uniform_cifar_fake_images[label_idx*5000:(1+label_idx)*5000] = generate_uniform_random_cifar_rgb_per_class(label_idx, num_samples, ifPlot = False)\n",
    "    _, _,synthetic_images = generate_uniform_random_cifar_rgb_per_class(label_idx, num_samples = num_samples, set_name = set_name)\n",
    "    plot_synthetic_images(synthetic_images, label_idx, set_name=set_name, number_of_rows_and_columns=5)\n",
    "os.system(f\"pdftk fake-{set_name}-class-*.pdf output fake-{set_name}.pdf\")\n",
    "os.system(f\"rm fake-{set_name}*class*\")\n",
    "    # print(tmp1.shape, tmp2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
